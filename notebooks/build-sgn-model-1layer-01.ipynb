{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import flopy\n",
    "\n",
    "# import specific FloPy modules\n",
    "from flopy.utils.gridgen import Gridgen \n",
    "from flopy.utils.gridintersect import GridIntersect\n",
    "\n",
    "# for working with shapefiles\n",
    "import shapefile as sf\n",
    "from shapely.geometry import Polygon, LineString, MultiLineString\n",
    "\n",
    "print(f'Flopy version:{flopy.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this notebook we will construct the SGN model. This is a model of a geothermal instalation in Milan. It is the same case-study site which is addressed in the PEST/PEST++ part of this course. However, the model used in the PEST/PEST++ class will be slightly diferent as it is constructed in Groundwater Vistas. The purpose of the current class is to demonstrate how to use Flopy using a real-world case and input files. \n",
    "\n",
    "## General Outline\n",
    "- For the current exercise, we will construct a model using MODFLOW6. This model will use a DISV grid type. This allows us to add zones of greater grid resolution, whilst retaining a layered approach. We will use the USGS software GRIDGEN to construct the model grid. GRIDGEN executables are in the \"bin\" folder. \n",
    "- Next we will create the MF6 simulation object, along with the time discretisation.\n",
    "- Then we will create the MF6 model object, based on the DISV grid created using GRIDGEN.\n",
    "- Then we will assign model properties and boundary conditions.\n",
    "- Next we will write the model files. At this stage you can inspect the MF6 input files if you wish (not a bad practice...)\n",
    "- Then we can run the model.\n",
    "- Then we can inspect the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "## Workspace and often accessed folders\n",
    "The \"workspace\" is the folder in which the model files will be written. Flopy needs to be informed where to read/write model files from.\n",
    "\n",
    "\n",
    "Depending on how input files and data are orgnaised, it may also be convenient to define the folder in which data files are stored (assuming we will be loading in lots of files from that folder throughout the model construction process). This is not a requirement, merely personal preference. For the current case, all input data files are housed in the folder \"..\\data\\sgn\".\n",
    "\n",
    "We will be using a few executables (*.exe) files trought this exercise. Usualy they should be in your PATH. Alterantively, you will need to specify the full path to the exectuable when it is called. They are housed in the \"bin\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the location of the model working directory; this is where all the MF6 files will be written\n",
    "# the folder path is relative to the location in which python is running. In our case, relative to the location of the jupyter notebok file.\n",
    "workspace = os.path.join('..','models','sgn_model_1layer')\n",
    "\n",
    "# Create the folder and make sure it is clean/empty.\n",
    "if os.path.exists(workspace):\n",
    "    shutil.rmtree(workspace)\n",
    "\n",
    "# the relative pathto the input file folder\n",
    "datadir = os.path.join('..','data','sgn')\n",
    "\n",
    "# the relative path to the executables folder\n",
    "bindir = os.path.join('..','bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you ran the previous cell, you will find a new directory in the repository folder \"models\" named \"sgn_model\". It will be empty, but this is where your model files will be going. It is usefull to chekc these files, specialy if a model is giving you trouble. When using GUI's (or flopy) users often lose touch with what is actualy going on with MODFLOW in the background. Get to know MODFLOW file structures. Trust me, you'll appreciate it in the long run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct the grid\n",
    "## GRIDGEN\n",
    "GRIDGEN allows you to create layered quad-tree refined model grids. It is possible to set up and run GRIDGEN using FlopY, allowing for easy grid construction and import.\n",
    "\n",
    "There are other ways to create unstructructured grids which FLopy can then use to build a model grid. TRIANGLE can be used to generate triangular or voronoi grids (there is a FloPy module to drive TRIANGLE as well). You can also write your own program to build grid inputs. Or you can use external software such as Algomesh or Processing Modflow to construct the grids and then import them. However, that kind of defeats the purpose of scripted model develpment. \n",
    "\n",
    "The FloPy git-hub repository has example notebooks on how to use the GRIDGEN and TRIANGLE modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the fullpath to the gridgen exe \n",
    "gridgen_exe = os.path.join(bindir, 'gridgen.exe')\n",
    "\n",
    "# gridgen will write a bunch of files; lets keep them seperate from the MF6 files, but within the same model workspace folder. To do so create a gridgen workspace sub-folder\n",
    "gridgen_ws = os.path.join(workspace, 'gridgen')\n",
    "if not os.path.exists(gridgen_ws):\n",
    "    os.makedirs(gridgen_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRIDGEN works off of a base structured MODFLOW grid. So first we need to define a \"base grid\". This is the smae as createing an old-school rectangular grid which covers the extent of the model we are going to construct. Think of it as a rectangle which covers the model extent. \n",
    "\n",
    "The \"box\" around the model area of interest which we wish to model is roughly 4500m by 5000 m. In the coordinate system in which all the input files are recorded, the coordinate of the upper left corner is aproximately x=1516500, y=5033650. The main direction of flow is roughly 14.1 deg.\n",
    "\n",
    "Let's create a grid with these conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the initial Grid\n",
    "# grid dimmensions\n",
    "Lx = 4150.\n",
    "Ly = 4810.\n",
    "xul, yul = 1516769.1487, 5033577.7911 # the upper left corner of the bounding box\n",
    "rot = 14\n",
    "\n",
    "# create a uniform cell size 100m x 100m\n",
    "delr = delc = 50 \n",
    "# calculate the number of rows and columns\n",
    "nrow = int(Ly / delc)\n",
    "ncol = int(Lx / delr)\n",
    "\n",
    "# The model will have 3 layers, but for the purposes of GRIDGEN this is not very relevant. The top and botom values for each layer are also not relevant yet, as we will have to obtain the cell elevations after grid refinmnet anyway. So we can just assign a dummy value for each and use a insgle layer for gridgen\n",
    "\n",
    "# we can then use the FloPy Modflow module to create a DIS object\n",
    "ms = flopy.modflow.Modflow(rotation=rot)\n",
    "dis = flopy.modflow.ModflowDis(ms, nlay=1, nrow=nrow, ncol=ncol, delr=delr,\n",
    "                               delc=delc, top=1, botm=0, xul=xul, yul=yul)\n",
    "\n",
    "# lets plot the bottom of the grid, just so we can see it makes sense\n",
    "#dis.botm.plot(colorbar=True, grid=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can instantiate a gridgen objct using the dis we just created.\n",
    "g = Gridgen(dis, model_ws=gridgen_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets quickly build that and see what it looks like\n",
    "# build the grid\n",
    "g.build(verbose=False)\n",
    "\n",
    "# Visualize the grid\n",
    "#fig = plt.figure(figsize=(4, 4))\n",
    "#ax = fig.add_subplot(1, 1, 1, aspect='equal')\n",
    "#g.plot(ax, linewidth=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thats great, but we wanted to add some refinment to certain areas. \n",
    "\n",
    "We wish to increase the refinement in a two zones of the model domain around an area of greater interest. These zones are outlined by a shapefile that we have in the \"data\" folder.\n",
    "\n",
    "We will start by loading the shapefile and then passing it to GRIDGEN to add refinment. For this we will use the \"shapefile\" library which we imported as \"sf\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path to the shapefile\n",
    "refine_shpfile = os.path.join(datadir, 'shp', 'Quadtree_level.shp')\n",
    "\n",
    "# use the sf.Reader function to load the shape as a sf Shapefile object\n",
    "refine_shp = sf.Reader(refine_shpfile).shapes()\n",
    "\n",
    "# see how many features are in the shape file\n",
    "print(f\"There are {len(refine_shp)} shapes in the shapefile.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to add diferent levels of refinement to each of those features\n",
    "# the input formats are a bit weird..I am sure there is a reason for it, but oh well\n",
    "# the add_refinment_features requires a list of list of tuples. The tuples contian the (x,y) coordinates of the refinment shape. \n",
    "refinment_level = 1\n",
    "for i in refine_shp:\n",
    "    g.add_refinement_features([[i.points]], 'polygon', refinment_level, [0])\n",
    "    #add +1 to the refinemnt level for the second polygon\n",
    "    refinment_level+=1\n",
    "\n",
    "# lets quickly build that and see what it looks like\n",
    "# build the grid\n",
    "g.build(verbose=False)\n",
    "\n",
    "# Visualize the grid\n",
    "#fig = plt.figure(figsize=(4, 4))\n",
    "#ax = fig.add_subplot(1, 1, 1, aspect='equal')\n",
    "#g.plot(ax, linewidth=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us also add refinement along the river\n",
    "# the path to the shapefile\n",
    "riv_shpfile = os.path.join(datadir, 'shp', 'River_Lambro.shp')\n",
    "# use the sf.Reader function to load the shape as a sf Shapefile object\n",
    "riv_shp = sf.Reader(riv_shpfile).shapes()\n",
    "# see how many features are in the shape file\n",
    "print(f\"There are {len(riv_shp)} shapes in the shapefile.\")\n",
    "\n",
    "# add refinement, this time define as line not polygon\n",
    "g.add_refinement_features([[riv_shp[0].points]], 'line', 1, [0])\n",
    "\n",
    "# lets quickly build that and see what it looks like\n",
    "# build the grid\n",
    "g.build(verbose=False)\n",
    "\n",
    "# Visualize the grid\n",
    "#fig = plt.figure(figsize=(5, 5))\n",
    "#ax = fig.add_subplot(1, 1, 1, aspect='equal')\n",
    "#g.plot(ax, linewidth=0.5);\n",
    "\n",
    "# lets also plot the shape file polygon that contains the desired model boundary, for comparison\n",
    "#flopy.plot.plot_shapefile(sf.Reader(os.path.join(datadir, 'shp', 'Model_domain.shp')), ax=ax, linewidth=1, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finaly, lets set the active domain\n",
    "# add the active domain\n",
    "boundary = sf.Reader(os.path.join(datadir, 'shp', 'Model_domain.shp')).shapes()\n",
    "g.add_active_domain([[boundary[0].points]], [0])\n",
    "\n",
    "# lets quickly build that and see what it looks like\n",
    "# build the grid\n",
    "g.build(verbose=False)\n",
    "\n",
    "# Visualize the grid\n",
    "#fig = plt.figure(figsize=(5, 5))\n",
    "#ax = fig.add_subplot(1, 1, 1, aspect='equal')\n",
    "#g.plot(ax, linewidth=0.5);\n",
    "#flopy.plot.plot_shapefile(sf.Reader(os.path.join(datadir, 'shp', 'Model_domain.shp')), ax=ax, linewidth=1, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created created a GRidGEN grid object, we can use inbuilt functions to obtain grid properties to construct the MODFLOW6 grid object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the grid properties and store them in rec array\n",
    "gridprops = g.get_gridprops_disv()\n",
    "# get the number of cell per layer\n",
    "ncpl = gridprops['ncpl']\n",
    "# get the number of vertices\n",
    "nvert = gridprops['nvert']\n",
    "#get the vertices and their coordinates\n",
    "vertices = gridprops['vertices']\n",
    "# get the cell2d properties\n",
    "cell2d = gridprops['cell2d']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the lists above are used as input when building a MF6 disv grid. But a few things are still missing:\n",
    "- number of layers. Our model is to have **ONE** layer.\n",
    "- the elevation of the top of the model. In the data folder there is a raster file of the DEM.\n",
    "- the elevation of the bootom of the layer. In the data folder there are raster files for the bottom of layer1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start by defining a variable for the number of layers, call it nlay\n",
    "nlay = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling from a raster file\n",
    "Next, we need to create an array (or list) of elevations for each cell to sign to the top of the model. We want to obtain these from the DEM raster. To do so, we need to obtain the elevation in the raster that coincides with the cell coordinates. For that, we need to know the cell coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the cell xy coordinates is easy-peasy\n",
    "cellxy = g.get_cellxy(ncpl)\n",
    "\n",
    "# anoyingly we actualy need separate lists of x and y coordinates\n",
    "cellx = cellxy[:,0]\n",
    "celly = cellxy[:,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the DEM raster\n",
    "# set the raster file path and name\n",
    "raster_file = os.path.join(datadir, 'raster', 'DTM_smooth.tif')\n",
    "\n",
    "# use the FloPy utils Raster object to load the raster file\n",
    "raster_dem = flopy.utils.Raster.load(raster_file)\n",
    "\n",
    "# we can even plot the raster while we are at it. Isnt that cool? Always good to check coordinate systems are the same, for example. \n",
    "#raster_dem.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can use the x and y cell coordinates to resample the DEM raster, tehre are several interpolation methods available, lets just use \"nearest\" because it is faster.\n",
    "# assign the values to a variable named \"top\". This will become an array of equal length to ncpl (number of cells per layer)\n",
    "top = raster_dem.resample_to_grid(cellx, \n",
    "                                  celly,\n",
    "                                  band=raster_dem.bands[0],\n",
    "                                  method=\"nearest\")\n",
    "print(f'top shape={top.shape}')\n",
    "print(f'ncpl={ncpl}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now lets create the data to define the bottom of each layer. This requires an array of shape (nlay, ncpl). In our case nlay = 1.\n",
    "\n",
    " Lets start by creating a dummy array with ones.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "botm = np.ones((nlay, ncpl))\n",
    "botm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to populate that array from the raster files of layer bottoms. I will do it the \"slow way\" so that it is easy to follow what is going on. It could be done alot more pythonicly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same for the two bottom rasters as we did for the DEM\n",
    "# set the file names\n",
    "raster_file_bot1 = os.path.join(datadir, 'raster', 'Bott_L1_fix.tif')\n",
    "# load the rasters\n",
    "raster_bot1 = flopy.utils.Raster.load(raster_file_bot1)\n",
    "\n",
    "# sample the rasters to the cell xy's\n",
    "botm[0] = raster_bot1.resample_to_grid(cellx, celly,band=raster_bot1.bands[0], method=\"nearest\")\n",
    "\n",
    "#botm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome, we are now ready to start constructing the MOFFLOW 6 model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODFLOW 6\n",
    "\n",
    "## The Simulation\n",
    "FloPy requires that we first create a \"simulation\" object. This simulation can have multiple models. There are a couple of things that you will generaly have to assign:\n",
    "- a Simulation package\n",
    "- a TDIS package\n",
    "- a MF6 Model, which will generaly require:\n",
    "    - an IMS (i.e. the solver settings) package\n",
    "    - a spatial discretisation (DIS, DISV or DISU) package\n",
    "    - initial condition package\n",
    "    - hydraulic property package(s)\n",
    "    - boundary condition pacakge(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the Flopy simulation object\n",
    "# if the MF6 executable is in your PATH, you can simply assign the string \"mf6\". If not, you need to specify the location of the executable as shown here:\n",
    "exe_name = os.path.join(bindir, 'mf6.exe')\n",
    "\n",
    "sim = flopy.mf6.MFSimulation(exe_name=exe_name,\n",
    "                             version=\"mf6\", \n",
    "                             sim_ws=workspace, \n",
    "                             continue_=True)  # This is an important setting for working with PEST/PEST++ it ensures the model will continue even if convergece is not achieved. Use with caution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The TDIS (time discretisation) object\n",
    "Time discretisation (i.e. the TDIS package) is defined at the simulation level. Lets instantioante a Tdis object. To do so, we need to define the stress period data.\n",
    "\n",
    "Stress period data needs to be passed to the Tdis object as a list of tuples. The list needs a tuple for each stress period. Each tuple contains the period length, the number of time steps and the time-sep multiplier:\n",
    " \\[(perlen, nstp, tsmult)]\n",
    "\n",
    "We will have a single steady-state stress-period and not considering transport, so period length does not matter. Number of time steps should be 1, and time-step multiplier does not matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use units of \"seconds\"; so all time related values must be in seconds\n",
    "time_units = 'seconds'\n",
    "\n",
    "#perioddata[perlen, nstp, tsmult]\n",
    "perioddata = [(1.0, 1, 1.0)] \n",
    "# set the number of periods, in this case 1\n",
    "nper= len(perioddata)\n",
    "\n",
    "\n",
    "# we can deinfe the sarting date_time; it doesnt matter here, but we will do so for demo purposes:\n",
    "start_date_time = '2021-06-01' #should be in the format '%Y-%m-%d'\n",
    "\n",
    "tdis = flopy.mf6.ModflowTdis(sim, pname=\"tdis\",\n",
    "                                  nper=nper, \n",
    "                                  perioddata=perioddata, \n",
    "                                  time_units=time_units, \n",
    "                                  start_date_time=start_date_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Flow Model\n",
    " Now we can create the FloPy MF6 model object and add the corresponding IMS package to the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Flopy groundwater flow (gwf) model object\n",
    "model_name = 'sgn'\n",
    "gwf = flopy.mf6.ModflowGwf(sim,\n",
    "                            modelname=model_name,\n",
    "                            save_flows=True, print_flows=True)\n",
    "\n",
    "# Instantiate a Flopy `IMS` Package object\n",
    "# Here you can set all the solver settings, all of these have default values so you dont need to specify them if the defaults are suficient.\n",
    "ims = flopy.mf6.ModflowIms(sim)\n",
    "\n",
    "# lastly we need to register the MF6 model to an IMS package in the Simulation\n",
    "sim.register_ims_package(ims, [gwf.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, you wouldnt necessarily start writting model files yet, but lets do so just to see what happens.\n",
    "sim.write_simulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the model workspace folder. You will see the files:\n",
    "\n",
    "\\['gridgen', 'mfsim.nam', 'sgn.nam', 'sim.ims', 'sim.tdis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The DISV package\n",
    "Right! So we can get back to assigning our model grid (Remember all that stuff we were doing earlier with GRIDGEN?).\n",
    "\n",
    "To do so, we create a FlopY DISV object with *flopy.mf6.ModflowGwfdisv()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating grid in mf6 with DISV\n",
    "# For disv input info: ncpl, nvert, vertices, cell2d (center x,y for each cell)\n",
    "length_units = \"METERS\"\n",
    "\n",
    "# create grid object\n",
    "disv = flopy.mf6.ModflowGwfdisv(gwf, nlay=nlay, ncpl=ncpl,length_units=length_units,\n",
    "                               top=top, botm=botm, nvert=nvert, vertices=vertices, cell2d=cell2d,\n",
    "                               idomain=[1])\n",
    "\n",
    "# we can plot it as well! \n",
    "# Lets check out the layer bottom elevations\n",
    "#disv.botm.plot()\n",
    "\n",
    "# we can also plot the top\n",
    "#disv.top.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zonning\n",
    "Our conceptal model is that the top aquifer (layer 1) has distinct geological zones. The aquiatrd and and lower aquifer are considered to be uniform geological units. The shape file *Geology_250000_clip.shp* defines the geological units in the upper aquifer.\n",
    "\n",
    "We will be assiginign diferent parameters to diferent zones. Additionaly, when you get to the PESt pat of this course, parameterisation will require zoning. To make life easier, we will distinguish between zones using different IDOMAIN values for each zone.\n",
    "\n",
    "Let's start by setting up the zones. Load in the shp file and inspect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path to the shapefile\n",
    "zones_shpfile = os.path.join(datadir, 'shp', 'Geology_250000_clip.shp')\n",
    "\n",
    "# Visualize the grid\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(1, 1, 1, aspect='equal')\n",
    "g.plot(ax, linewidth=0.5);\n",
    "\n",
    "# lets  plot the shape file \n",
    "flopy.plot.plot_shapefile(sf.Reader(zones_shpfile), ax=ax, linewidth=1, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see. There are several polygons within the model domain. However there are only suposed to be two zones. Lets inspect the shapefile records (i.e. the \"attribute table\" if you open it in QGIS or ArcGIS).\n",
    "\n",
    "Use the sf.Reader *records()* method to inspect the shapefile records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones_records = sf.Reader(zones_shpfile).records()\n",
    "zones_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as it is a list, you can access the record for each shape by indexing\n",
    "zones_records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and then specific attributes within the shape record by indexing again\n",
    "zones_records[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also use the sf.Reader.record() function to access specifc records. Note record vs records. The \"s\" refers to a diferent method.\n",
    "sf.Reader(zones_shpfile).record(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you see there is a list of lists. Each sub-list contians the recoords assocaited to each polygon (i.e. shape) in the **zones_shpfile**.\n",
    "\n",
    "As you can see, the information repeats. So there are multiple \"shapes\", but they all belong to one of two geological units. The numeric code for each unit is given as the first element of the sub-list. In this case, either \"301\" or \"205\", which correspon to the \"alluvial deposits\" and \"sands and gravels\" respectively. \n",
    "\n",
    "To assign zones in the model, we need to know which cells coincide with those zones. To accomplish this for the zones in the top layer we shall use FloPy's GridIntersect module: *flopy.utils.gridintersect.GridIntersect* which we have imported as *GridIntersect*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridIntersect works by first calling an intersect object on the model grid:\n",
    "ix = GridIntersect(gwf.modelgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Once ix is instantiated, you can now call interscets on the grid using shapely objects\n",
    "# use the sf.Reader function to load a list of sf Shapefile objects\n",
    "zones_shp = sf.Reader(zones_shpfile).shapes()\n",
    "\n",
    "# As there are multiple shapes in the zones_shpfile, zones_shp is a list of shapely objects.\n",
    "# GridIntersect needs to be applied to each shape in that list of shapes.\n",
    "# For example, applying to the first shape in the list returns:\n",
    "x = ix.intersect(zones_shp[0])\n",
    "\n",
    "# x is a numpy rec.array containting a bunch of information on the intersection between the shape and the model grid.\n",
    "# it can be easier to visualize as a Pandas dataframe as shown below\n",
    "# x contains the cellids of model cells intersected by the first shape in zones_shp, as well as the vertices and area of the interesected(!) part of the cell\n",
    "pd.DataFrame(x).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can access cellids or areas directly through the rec.array attributes, by using x.areas or x.cellids\n",
    "x.cellids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So now, we can loop through all the shapes and idntify cellids which belong to each zone\n",
    "# we will assign corresponding zone numbers to the Idomain array so that we can reuse them in future\n",
    "# You can acces the idomain values for each layer from the disv object like thus: disv.idomain.data\n",
    "disv.idomain.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alluviums will be assigned to zone 4, gravels to zone 1\n",
    "# as we assigned values of 1 to idomain be default, we only need to update cells that interesect alluviaums (i.e. zone 4)\n",
    "# Note that this will include ANY cell intersected by the polygon shape. So it can include cells that only have a small portion of thier area included in the geological zone. In practice you may wish to consider more elabraote selection criteria (i.e. minimum % of cell area or something like that).\n",
    "a = disv.idomain.data[0]\n",
    "\n",
    "for i in range(len(zones_shp)):\n",
    "    shp = zones_shp[i]\n",
    "    geo_code = zones_records[i][0]\n",
    "    if geo_code == 301:\n",
    "        x = ix.intersect(shp).cellids.astype(int)\n",
    "        a[x] = 4\n",
    "\n",
    "# update the disv idomain values using the .set_data() method\n",
    "disv.idomain.set_data(a, layer=0)\n",
    "\n",
    "# now lets chck the disv idomain values in layer 1\n",
    "\n",
    "\n",
    "# Visualize the grid\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "# plot idomain for top layer\n",
    "disv.idomain.plot(colorbar=True, mflay=0)\n",
    "# plot the shape file \n",
    "flopy.plot.plot_shapefile(sf.Reader(zones_shpfile), linewidth=2, facecolor='grey', edgecolor='w', alpha=0.3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial conditions\n",
    "### The intial condition (IC) package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the initial conditions with the IC package\n",
    "# you can set a single value for the entire model\n",
    "strt = 50 \n",
    "# or assign discrete values per layer\n",
    "strt = [50,10,0]\n",
    "# or even set the same value for each cell, the same in each layer. For example, equal to tthe array we used to defient he model top. Lets do that:\n",
    "strt = nlay*[top]\n",
    "\n",
    "ic = flopy.mf6.ModflowGwfic(gwf, pname=\"ic\", strt=strt)\n",
    "strt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hydraulic conductivity\n",
    "### per model zone\n",
    "As we did for strt, k can be assigned per individual cell, layer, or as a single constant value. Recall that we are using units of \"meter\" and \"seconds\". So k must be passed as units of \"m/s\".\n",
    "\n",
    "From our model brief, we have been given distinct values of for all four zones. Let us assign unique values per zone. Conveniently, we can use the Idomain values to \"select\" cells from each zone.\n",
    "\n",
    "zone1 (shallow aquifer; layer 1): 2.3E-3 m/s <br>\n",
    "zone4 (shallow aquifer; layer 1): 4.1E-3 m/s <br>\n",
    "zone2 (aquitard): 1E-08 m/s <br>\n",
    "zone3 (deep aquifer): 2.3E-3 m/s<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us start by creating a template for our k input data; we can do so easily enough by making a copy of the idomain. \n",
    "k = disv.idomain.data.copy().astype('float')\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now it is a simple to task to slice the k array to assign the values we want\n",
    "# update the values for each zone\n",
    "k[k==1] = 2.3E-3 \n",
    "#k[k==2] = 1E-08\n",
    "#k[k==3] = 2.3E-3 \n",
    "k[k==4] = 4.5E-3\n",
    "\n",
    "# see if that worked\n",
    "np.unique(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the MODFLOW6 NPF pacakge variables can be assigned to the FloPy *flopy.mf6.ModflowGwfnpf* object. We also want to set the k vertical anisotropy to have a ratio of 0.1 (i.e.  kv = kh/10). This can be assigned using the k33 variable. Vertical hydraulic conductivity can be assinged explicitly (i.e. kv = 1e-3 m/s) or as a ratio. In both cases the k33 variable is used. Defining whether k33 is a ratio is defined with k33overk variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique values per layer\n",
    "npf = flopy.mf6.ModflowGwfnpf(gwf, k=k, \n",
    "                              save_flows=True, \n",
    "                              save_specific_discharge=None, \n",
    "                              k33=0.1, k33overk=True)\n",
    "\n",
    "# and to see if it worked...\n",
    "npf.k.plot(colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with PEST/PEST++, it is usualy good practice to set packages to write model input data to external files. You will learn more about this in the PEST module of this course. To do, you can simply write *npf.set_all_data_external()*. However, this writes ALL the NPF package files. This can get messy...\n",
    "\n",
    "Alterantively, you can  specify which files to write using the *npf.k.store_as_external_file()*, for example. Lets do this for the K parameters of all three layers.\n",
    "\n",
    "To do so, we need to specify the external file and path. You can specify to store values individualy per layer, or all in a single file. Which to choose depends on your case...Let us store the values of K for each layer in a seperate file. Let us name each file with the model name followed by the letter \"k\" and the layer number (i.e. sgn.k1.txt)\n",
    "\n",
    "Note that this function will write the package files imediately, not requiring the *sim.write_simulation()* call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write files externaly\n",
    "for lay in range(nlay):\n",
    "    external_file_path =  f'{gwf.name}.k{lay+1}.txt' # layer + 1 because FloPy is zero indexed\n",
    "    npf.k.store_as_external_file(external_file_path=external_file_path,layer=lay)\n",
    "\n",
    "# Check the model workspace folder.  You will see the three new files written \n",
    "for f in os.listdir(workspace):\n",
    "    if '.k' in f:\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets write the simulation files again so that we can check what FloPy is doing. Run *sim.write_simultion()* and then inspect the files in your model workspace folder. The *sgn.npf* file has the details of the NPF package, with arrays of K per alyer written in the external files. You can open any of these files in a text editor or even here in your notebook as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.write_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the model workspace folder. \n",
    "os.listdir(workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the npf file\n",
    "with open(os.path.join(workspace, f'{gwf.name}.npf'), 'r') as f:\n",
    "    a = f.readlines()\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recharge\n",
    "### Set the recharge over the top layer\n",
    "We are going to assing a recharge rate to the top layer. We have been provided with a .shp file of recharge polygons which is the file named \"Recharge_4.shp\" in the data folder.\n",
    "\n",
    "The shp polygons do not match our grid, so we need to assign spatialy weighted values of interesected shp polygons to each model cell. The shp file contains recharge rates stored as mm/yr in the \"records\". The model units are m/s. So values also need to be converted to the correct units.\n",
    "\n",
    "To accomplish this we shall use FloPy's GridIntersect module: *flopy.utils.gridintersect.GridIntersect* which we have imported as *GridIntersect*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path to the shapefile\n",
    "rch_shpfile = os.path.join(datadir, 'shp', 'Recharge_4.shp')\n",
    "# use the sf.Reader function to load the shape as a sf Shapefile object\n",
    "rch_shp = sf.Reader(rch_shpfile).shapes()\n",
    "\n",
    "# Visualize the grid\n",
    "#fig = plt.figure(figsize=(5, 5))\n",
    "#gwf.modelgrid.plot(linewidth=0.5, alpha=0.5)\n",
    "# lets  plot the shape file \n",
    "#flopy.plot.plot_shapefile(sf.Reader(rch_shpfile),linewidth=1, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the records; the recharge rate (mm/yr) is the last element of the record. Zero in hte case shwon below:\n",
    "sf.Reader(rch_shpfile).record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to get the areas of all cells. As we used GRIDGEN to generate the grid, we COULD access cell areas from the gridgen object using \"g.get_area()\"\n",
    "# However, if the grid were generated in another way we would need an alternative method.\n",
    "g.get_area()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets isntead get the cell areas using GridIntersect as this is a more generalizable case.\n",
    "# To do so, we create a polygon which extends over the enitre model domain and intersect the grid\n",
    "# We create the polygon using the shapely.geometry Polygon module that we imported at the beggingin\n",
    "# get the x and y coordiantes fro the boundaing box; \n",
    "xmin, xmax = disv.vertices.array['xv'].min(), disv.vertices.array['xv'].max()\n",
    "ymin, ymax = disv.vertices.array['yv'].min(), disv.vertices.array['yv'].max()\n",
    "# make the polygon\n",
    "bbox = Polygon(shell=[(xmin, ymin), (xmax, ymin), (xmax, ymax), (xmin, ymax)])  #Polygon(shell=model_vertices_xy, holes=[])\n",
    "\n",
    "# ineresect all model cells\n",
    "bbox = ix.intersect(bbox)\n",
    "\n",
    "# get the areas of all interesected cells\n",
    "cell_areas = bbox.areas\n",
    "\n",
    "if ncpl == cell_areas.shape:\n",
    "    print(\"I think we got'em all cap'n!\")\n",
    "\n",
    "# note that values are slightly differnt, but not significantly so.\n",
    "cell_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have all that we need to start building the RCH package input.\n",
    "# We can cyclce through each intersect, and fill in the RCH stress period data as we go\n",
    "# Start by creating the rch spd list which we will populate\n",
    "spd_rch = []\n",
    "\n",
    "# for checking purposes\n",
    "tot_recharge = 0\n",
    "\n",
    "# for each feature in the shapefile\n",
    "for i in range(len(rch_shp)):\n",
    "    shp = rch_shp[i]\n",
    "    # the shapefile records contain the recharge rate in the last attribute \"column\"; these values must be converetd from mm/yr to m/s\n",
    "    rch_rate = sf.Reader(rch_shpfile).record(i)[-1]/1000/365/24/60/60\n",
    "    # get the intersect\n",
    "    intersect = ix.intersect(shp)\n",
    "\n",
    "    for cellix in intersect:\n",
    "        # get the cell id\n",
    "        icpl = cellix.cellids\n",
    "        # get the intersected area\n",
    "        cellarea = cellix.areas\n",
    "        # get the total area of the cell\n",
    "        totarea = cell_areas[icpl]\n",
    "        # we can use the multipler variable to adjust the recharge rate to the effective area of the cell which is intersected\n",
    "        mult = cellarea/totarea\n",
    "    \n",
    "        # append to the rch spd list\n",
    "        spd_rch.append(((0, icpl), rch_rate, mult, 'rch'))\n",
    "\n",
    "        # for checking purposes\n",
    "        tot_recharge += (rch_rate * cellarea)\n",
    "\n",
    "\n",
    "# assign the spd data to the RCH package\n",
    "rch = flopy.mf6.ModflowGwfrch(gwf, filename='{}.rch'.format(model_name), \n",
    "                               pname='rch', \n",
    "                               auxiliary='MULTIPLIER', auxmultname='MULTIPLIER', boundnames=True,\n",
    "                               print_input=True, print_flows=True, save_flows=True,\n",
    "                               stress_period_data=spd_rch, maxbound=84)\n",
    "\n",
    "# added observation timeseries of recharge so that you can check the mdoel outputs\n",
    "rch_obs = {('rch.csv'): [('rch', 'RCH', 'rch')]}\n",
    "\n",
    "rch.obs.initialize(digits=9, print_input=False, \n",
    "                   continuous=rch_obs)\n",
    "\n",
    "# if we parameterize recharge using PEST...\n",
    "rch.set_all_data_external()\n",
    "\n",
    "# we will use this value as a check to confirm our model outputs later\n",
    "print(f'Recharge: {tot_recharge} m3/s')\n",
    "print(f'Recharge: {tot_recharge * 60*60*24*365} m3/yr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## River BC\n",
    "On the east side of the model, the First aquifer could be in communication with the River Lambro, which is inserted in the model as a RIVER condition (Figure 10). The levels of the watercourse were taken from LIDAR quotas and compared with the hydrometer upstream of the model area (Stazione 869 Milano v. Feltre, Figure 11):\n",
    " - Hydrometer altitude: average level September 2019: 69.05 cm from hydrometric zero (115.1 m asl) = 115.79 m asl;\n",
    " - LIDAR altitude in correspondence with the Hydrometer: 116.2 m asl.\n",
    "\n",
    "\n",
    "River stages are stored in the shapefile: *River_stages_polyline.shp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path to the shapefile\n",
    "riv_shpfile = os.path.join(datadir, 'shp', 'River_stages_polyline.shp')\n",
    "# use the sf.Reader function to load the shape as a sf Shapefile object\n",
    "riv_shapes = sf.Reader(riv_shpfile).shapes()\n",
    "\n",
    "\n",
    "riv_spd=[]\n",
    "# for each feature in the shapefile\n",
    "for i in range(len(riv_shapes)):\n",
    "    shp = riv_shapes[i]\n",
    "    # the shapefile records contain the stage in the first attribute \"column\";\n",
    "    stage = sf.Reader(riv_shpfile).record(i)[0] - 0.4\n",
    "    # get the intersect\n",
    "    cellids = ix.intersect(shp).cellids\n",
    "    cond = 0.001\n",
    "    rbot = stage - 1.0\n",
    "    for icpl in cellids:\n",
    "        riv_spd.append(((0, icpl), stage, cond, rbot, 'riv')) #[cellid, stage, cond, rbot, aux, boundname]\n",
    "\n",
    "\n",
    "#initilize pacakge\n",
    "riv = flopy.mf6.ModflowGwfriv(gwf, stress_period_data=riv_spd, boundnames=True)\n",
    "\n",
    "# build obs data\n",
    "riv_obs = { ('riv.csv'):[('riv', 'RIV', 'riv')]}\n",
    "\n",
    "# initialize obs package\n",
    "riv.obs.initialize(digits=9, print_input=False,continuous=riv_obs)\n",
    "\n",
    "riv.set_all_data_external()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = plt.figure(figsize=(5, 5))\n",
    "#ax = fig.add_subplot(1, 1, 1, aspect='equal')\n",
    "\n",
    "# use PlotMapView to plot a DISV  model\n",
    "#m = flopy.plot.PlotMapView(gwf, layer=0)\n",
    "#riv = m.plot_bc(\"RIV\")\n",
    "#linecollection = m.plot_grid(linewidth=0.5, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set all surfaces cells as DRN to avoid \"flooding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all surface to drain\n",
    "drnspd = {}\n",
    "drnspd_i = []\n",
    "for i in range(ncpl):\n",
    "    drnu_spd = [(0, i), gwf.dis.top.get_data()[i], 10000, 'surf-drn']\n",
    "    drnspd_i.append(drnu_spd)\n",
    "\n",
    "drnspd[0] = drnspd_i\n",
    "\n",
    "#initilize pacakge\n",
    "drn = flopy.mf6.ModflowGwfdrn(gwf, stress_period_data=drnspd, boundnames=True)\n",
    "\n",
    "# build obs data\n",
    "drn_obs = { ('drn_surf.csv'):[('surf-drn', 'DRN', 'surf-drn')]}\n",
    "\n",
    "# initialize obs package\n",
    "drn.obs.initialize(digits=9, print_input=False,continuous=drn_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = plt.figure(figsize=(5, 5))\n",
    "#ax = fig.add_subplot(1, 1, 1, aspect='equal')\n",
    "\n",
    "# use PlotMapView to plot a DISV  model\n",
    "#m = flopy.plot.PlotMapView(gwf, layer=0)\n",
    "#riv = m.plot_bc(\"DRN\")\n",
    "#linecollection = m.plot_grid(linewidth=0.5, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEll BCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path to the shapefile\n",
    "wel_shpfile = os.path.join(datadir, 'shp', 'wells.shp')\n",
    "# use the sf.Reader function to load the shape as a sf Shapefile object\n",
    "wel_shapes = sf.Reader(wel_shpfile).shapes()\n",
    "\n",
    "\n",
    "wel_spd=[]\n",
    "wel_obs_list=[]\n",
    "\n",
    "# for each feature in the shapefile\n",
    "for i in range(len(wel_shapes)):\n",
    "    shp = wel_shapes[i]\n",
    "    # the shapefile records contain the stage in the first attribute \"column\";\n",
    "    record = sf.Reader(wel_shpfile).record(i)\n",
    "    pump_rate = record[-1]\n",
    "    well_id = record[0]\n",
    "    top_lay = record[3]-1\n",
    "    bot_lay = record[4]-1\n",
    "\n",
    "    if top_lay==0:\n",
    "        wel_obs_list.append((f'well-{well_id}', 'WEL', f'well-{well_id}'))\n",
    "\n",
    "        # get the intersect\n",
    "        cellids = ix.intersect(shp).cellids\n",
    "        for icpl in cellids:\n",
    "            wel_spd.append(((0, icpl), pump_rate, f'well-{well_id}')) #[cellid, stage, cond, rbot, aux, boundname]\n",
    "\n",
    "\n",
    "wel = flopy.mf6.ModflowGwfwel(gwf, stress_period_data=wel_spd, boundnames=True)\n",
    "\n",
    "# build obs data \n",
    "wel_obs = {('wells.csv'): wel_obs_list}\n",
    "\n",
    "# initialize obs package\n",
    "wel.obs.initialize(digits=9, print_input=True, \n",
    "                   continuous=wel_obs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "for i in range(nlay):\n",
    "    ax = fig.add_subplot(1, 3, i+1, aspect='equal')\n",
    "    ax.set_title(f\"WEL in layer{i+1}\")\n",
    "    # use PlotMapView to plot a DISV  model\n",
    "    m = flopy.plot.PlotMapView(gwf, layer=i)\n",
    "    riv = m.plot_bc(\"WEL\")\n",
    "    linecollection = m.plot_grid(linewidth=0.5, alpha=0.5)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GHB outer boundary\n",
    "\n",
    "In order to reproduce the regional flow, the model boundaries were defined by imposing General Head Boundary (GHB) boundary conditions around the model boundary. The values assigned to the GHB conditions were entered taking into account the results of the September 2019 field msurment campaign.\n",
    "\n",
    "### Note:\n",
    "At this stage this model will diverge a bit from that which is constructed with GW Vistas. BCs for GHB heads are assigned in a slightly different manner. Here we will assign values directly from an inpolated surface if piezometric measuremnts. iIn the GW Vistas version, values are assigned according to an interpreted linear gradient along the model boundary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the points of the polygon shapefile used to create the model boundary\n",
    "boundary_points = sf.Reader(os.path.join(datadir, 'shp', 'Model_domain.shp')).shape(0).points\n",
    "\n",
    "#transform into a polyline\n",
    "boundary_line = LineString(boundary_points)\n",
    "\n",
    "# now we can intersect and ge tthe cellids of cells along the model boundary\n",
    "# use .buffer() on the sahpely object to interesect bounday lines\n",
    "ix_boundary = ix.intersect(boundary_line.buffer(25,  resolution=4))\n",
    "\n",
    "# confirm that intersect worked as intended:\n",
    "#fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "#gwf.modelgrid.plot(ax=ax)\n",
    "#ix.plot_linestring(ix_boundary, ax=ax)\n",
    "# plot a black x at intersected cell centers\n",
    "#for i in ix_boundary.cellids:\n",
    "#    ax.plot(gwf.modelgrid.xcellcenters[i], gwf.modelgrid.ycellcenters[i], \"kx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a raster with interpolated hydralic heads from a afield campaign in september 2019\n",
    "# set the raster file path and name\n",
    "raster_file = os.path.join(datadir, 'raster', 'heads_sep2019.asc')\n",
    "# use the FloPy utils Raster object to load the raster file\n",
    "raster_heads = flopy.utils.Raster.load(raster_file)\n",
    "# and plot \n",
    "raster_heads.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets build up the GHB stress period data \n",
    "cellx = np.array(gwf.modelgrid.xcellcenters)\n",
    "celly = np.array(gwf.modelgrid.ycellcenters)\n",
    "head = raster_heads.resample_to_grid(cellx, celly,band=raster_heads.bands[0], method=\"nearest\")\n",
    "\n",
    "ghb_spd =[]\n",
    "ghb_obs_list=[]\n",
    "for icpl in ix_boundary.cellids:\n",
    "    cond = 100.0\n",
    "    for layer in [0]:\n",
    "        ghb_spd.append([(layer, icpl), head[icpl], cond, f'GHB{layer+1}'])\n",
    "        ghb_obs_list.append((f'GHB{layer+1}', 'GHB', f'GHB{layer+1}'))\n",
    "\n",
    "# create the package\n",
    "ghb = flopy.mf6.ModflowGwfghb(model=gwf, \n",
    "                                stress_period_data=ghb_spd, \n",
    "                                boundnames=True)  \n",
    "\n",
    "# build obs data\n",
    "ghb_obs = {('ghb.csv'):ghb_obs_list}\n",
    "\n",
    "# initialize obs package\n",
    "ghb.obs.initialize(digits=9, print_input=True, \n",
    "                   continuous=ghb_obs)\n",
    "\n",
    "ghb.set_all_data_external()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 5))\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1, aspect='equal')\n",
    "ax.set_title(f\"GHB in layer{i+1}\")\n",
    "# use PlotMapView to plot a DISV  model\n",
    "m = flopy.plot.PlotMapView(gwf, layer=0)\n",
    "riv = m.plot_bc(\"GHB\")\n",
    "linecollection = m.plot_grid(linewidth=0.5, alpha=0.5)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path to the shapefile\n",
    "obs_shpfile = os.path.join(datadir, 'shp', 'Target_L1_Jan2020.shp')\n",
    "# use the sf.Reader function to load the shape as a sf Shapefile object\n",
    "obs_shapes = sf.Reader(obs_shpfile).shapes()\n",
    "\n",
    "\n",
    "obs_list=[]\n",
    "# for each feature in the shapefile\n",
    "for i in range(len(obs_shapes)):\n",
    "    \n",
    "    shp = obs_shapes[i]\n",
    "    cellids = ix.intersect(shp).cellids\n",
    "\n",
    "    record = sf.Reader(obs_shpfile).record(i)\n",
    "    piezid = record[0]\n",
    "    for icpl in cellids:\n",
    "        obs_list.append((f'{piezid}', 'HEAD', (0, icpl))) # assume layer 1\n",
    "\n",
    "obs_recarray = {'head_obs.csv':obs_list}\n",
    "\n",
    "# initialize obs package\n",
    "obs_package = flopy.mf6.ModflowUtlobs(gwf, \n",
    "                                      digits=10, print_input=True,\n",
    "                                      continuous=obs_recarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output control (OC) package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "# output control\n",
    "oc = flopy.mf6.ModflowGwfoc(gwf, pname='oc', \n",
    "                            budget_filerecord='{}.cbb'.format(model_name),\n",
    "                            head_filerecord='{}.hds'.format(model_name),\n",
    "                            headprintrecord=[('COLUMNS', 10, 'WIDTH', 15,\n",
    "                                              'DIGITS', 6, 'GENERAL')],\n",
    "                            saverecord=[('HEAD', 'LAST'), ('BUDGET', 'LAST')],\n",
    "                            printrecord=[('HEAD', 'LAST'), ('BUDGET', 'ALL')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.write_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.run_simulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Processing\n",
    "## Load the budget list file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_list = flopy.utils.Mf6ListBudget(os.path.join(workspace, f\"{gwf.name}.lst\"), timeunit='seconds') #MF6ListBudget is different from MfListBudget...*sigh*\n",
    "incremental, cumulative = mf_list.get_budget()\n",
    "incrementaldf, cumulativedf = mf_list.get_dataframes(start_datetime=\"01-09-2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incrementaldf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Heads file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.join(workspace, model_name + '.hds')\n",
    "hdobj = flopy.utils.HeadFile(fname, model=gwf)\n",
    "head = hdobj.get_alldata()\n",
    "\n",
    "hmin = head.min()\n",
    "hmax = head.max()\n",
    "\n",
    "print(f'Max head in model run: {hmax}')\n",
    "print(f'Min head in model run: {hmin}')\n",
    "\n",
    "head.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the times at which values are recorede in the heads file\n",
    "hdtimes = hdobj.get_times()\n",
    "hdtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can export heads to a shp file for display in a GIS, for example\n",
    "hdobj.to_shapefile(os.path.join(workspace, \"sim-heads.shp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic plot of head data\n",
    "hdobj.plot(mflay=0, totim=hdtimes[0] ,colorbar=True, contour=True, clabel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A (slightly) more elaborate figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the model grd file\n",
    "fname = os.path.join(workspace, f'{gwf.name}.disv.grb')\n",
    "grd = flopy.utils.MfGrdFile(fname, verbose=False)\n",
    "iverts, verts = grd.get_verts()\n",
    "vertc = grd.get_centroids()\n",
    "mg = grd.get_modelgrid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cint = (hmax-hmin)/10\n",
    "lims = [hmin, hmax]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10), tight_layout=True)\n",
    "x = 1\n",
    "\n",
    "for timestep in range(0, head.shape[0]):\n",
    "    for i in range(nlay):\n",
    "        ax = fig.add_subplot(3, 3, x, aspect='equal', sharex=ax, sharey=ax)\n",
    "        x+=1\n",
    "\n",
    "        mm = flopy.plot.PlotMapView(model=gwf, ax=ax)\n",
    "\n",
    "        # plot the model grid + fill contours\n",
    "        # heads\n",
    "        h = mm.plot_cvfd(verts, iverts, edgecolor='grey', a=head[timestep,i, 0, :], cmap='RdYlBu', alpha=1, vmin=hmin, vmax=hmax, linewidth=0.1)\n",
    "        cb = plt.colorbar(h, shrink=0.5, pad=0.01)\n",
    "\n",
    "        \n",
    "        # plot isolines\n",
    "        levels = np.arange(np.floor(hmin), np.ceil(hmax) + cint, cint)\n",
    "        cs = mm.contour_array_cvfd(vertc, head[timestep,i, 0, :], colors='white', levels=levels)\n",
    "\n",
    "        plt.clabel(cs, fmt='%.1f', colors='white', fontsize=8)\n",
    "\n",
    "        # plot the well cells\n",
    "        wells = mm.plot_bc(\"WEL\")\n",
    "        \n",
    "        # set titles\n",
    "        t = ax.set_title('Layer {}; end of spd={}'.format(i + 1,timestep), fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}