{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbb7115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../dependencies/')\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from rasterio import features\n",
    "import geopandas as gp\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, LineString"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070f0869",
   "metadata": {},
   "source": [
    "# Let's check out the proposed domain to get some coordiante information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dac6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = Path('../../data/sgn/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa1b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = gp.read_file(datapath / 'shp' / 'Model_domain.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471b54dc",
   "metadata": {},
   "source": [
    "### what's the projection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752d3c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1843f875",
   "metadata": {},
   "source": [
    "### and what are the bounding points? We can navigate this using min and max x and y points because we know the rotation is anticlockwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240cd48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = domain.geometry[0].exterior.coords.xy\n",
    "xul, yul = x[np.argmin(x)],y[np.argmin(x)]\n",
    "xtop, ytop = x[np.argmax(y)],y[np.argmax(y)]\n",
    "xll, yll = x[np.argmin(y)],y[np.argmin(y)]\n",
    "xlr,ylr = x[np.argmax(x)],y[np.argmax(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05f197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = domain.plot(color=None)\n",
    "ax.plot(xul,yul, 'x')\n",
    "ax.plot(xtop,ytop, 'o')\n",
    "ax.plot(xll,yll,'*')\n",
    "ax.plot(xlr,ylr,'d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e72ec9c",
   "metadata": {},
   "source": [
    "### calculate the angle of rotation from upper left and top vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310dbfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "opp_over_hyp = np.abs(ytop-yul)/np.sqrt((xtop-xul)**2+(ytop-yul)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9883569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "opp_over_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ec2577",
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_angle = np.arcsin(opp_over_hyp)\n",
    "rot_angle = float(rot_angle * 180/np.pi)\n",
    "rot_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b6ee59",
   "metadata": {},
   "source": [
    "# calculate the total length and width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5569266",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = np.round(np.sqrt((xll-xul)**2+(yll-yul)**2), decimals=-1)\n",
    "width = np.round(np.sqrt((xll-xlr)**2+(yll-ylr)**2), decimals=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5129b580",
   "metadata": {},
   "source": [
    "### check out the recharge and geology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d061cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rch = gp.read_file(datapath / 'shp' / 'Recharge_4.shp')\n",
    "rch.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c935d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rch.plot(column = 'RCH_mmy', legend=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ff0c76",
   "metadata": {},
   "source": [
    "### it's easier if we burn this into a raster for `modflow-setup` to handle ATM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdee4d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open layer 2 bottom and read the metadata for the raster\n",
    "bot2_rast = rasterio.open(datapath/ 'raster' / 'Bott_L2_fix.tif') \n",
    "rastermeta = bot2_rast.meta.copy()\n",
    "rastermeta.update(compress='lzw') # set compression to be sure file is small as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c746ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a tuple of geomoetry/k-value pairs from the geology shapefile\n",
    "rchpolygons = ((geom,value) for geom, value in zip(rch.geometry, rch.RCH_mmy))\n",
    "with rasterio.open(datapath/ 'raster' / 'rch.tif', 'w+', **rastermeta) as ofp:\n",
    "    out_arr = ofp.read(1)\n",
    "    \n",
    "    rchraster = features.rasterize(shapes=rchpolygons,\n",
    "                                       fill=-9999,\n",
    "                                       out=out_arr,\n",
    "                                       transform=ofp.transform)\n",
    "    ofp.write_band(1,rchraster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfb508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm we wrote this ok\n",
    "with rasterio.open(datapath/ 'raster' / 'rch.tif') as src:\n",
    "    rch = src.read(1)\n",
    "rch[rch<-1] = np.nan\n",
    "plt.imshow(rch)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1eb43e",
   "metadata": {},
   "source": [
    "### now let's check out the geology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9c1209",
   "metadata": {},
   "outputs": [],
   "source": [
    "geology = gp.read_file(datapath / 'shp' / 'Geology_250000_clip.shp')\n",
    "geology.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120ff629",
   "metadata": {},
   "outputs": [],
   "source": [
    "geology.plot(column = 'LITOLOGIA', legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0603091f",
   "metadata": {},
   "source": [
    "### we can set starting Kh values as: \n",
    "Gravel and sand = 0.0045  \n",
    "Gravel, sand and silt = 0.0023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007edf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "geology['k'] = -999999\n",
    "geology.loc[geology.LITOLOGIA == 'Gravel and sand', 'k'] = 0.0045\n",
    "geology.loc[geology.LITOLOGIA == 'Gravel, sand and silt', 'k'] = 0.0023\n",
    "assert geology.k.min()>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90b9dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "geology.plot(column='k', legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb6ed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a tuple of geomoetry/k-value pairs from the geology shapefile\n",
    "geopolygons = ((geom,value) for geom, value in zip(geology.geometry, geology.k))\n",
    "with rasterio.open(datapath/ 'raster' / 'k_field0.tif', 'w+', **rastermeta) as ofp:\n",
    "    out_arr = ofp.read(1)\n",
    "    \n",
    "    georaster = features.rasterize(shapes=geopolygons,\n",
    "                                       fill=-9999,\n",
    "                                       out=out_arr,\n",
    "                                       transform=ofp.transform)\n",
    "    ofp.write_band(1,georaster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996aca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm we wrote this ok\n",
    "with rasterio.open(datapath/ 'raster' / 'k_field0.tif') as src:\n",
    "    k0 = src.read(1)\n",
    "k0[k0<-1] = np.nan\n",
    "plt.imshow(k0)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5fdd17",
   "metadata": {},
   "source": [
    "### for now, we will assign constant values to layers 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2167dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = np.ones_like(k0) * 1e-8 # aquitard\n",
    "k2 = np.ones_like(k0) * 2.3e-3 # deep aquifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6103c598",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(datapath/ 'raster' / 'k_field1.tif', 'w+', **rastermeta) as ofp:\n",
    "    ofp.write_band(1, k1)\n",
    "with rasterio.open(datapath/ 'raster' / 'k_field2.tif', 'w+', **rastermeta) as ofp:\n",
    "    ofp.write_band(1, k2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc951be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8ee70a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03ee5b2a",
   "metadata": {},
   "source": [
    "### and let's see where the river is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49bd622",
   "metadata": {},
   "outputs": [],
   "source": [
    "riv = gp.read_file(datapath / 'shp' / 'River_Lambro.shp')\n",
    "riv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d1c4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = geology.plot(column='k', legend=True)\n",
    "riv.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b580d0e1",
   "metadata": {},
   "source": [
    "### we need to add some information to the river"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95d9f4d",
   "metadata": {},
   "source": [
    "#### first break up into a handful of segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61b543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "riv1 = riv.iloc[0].geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2b2045",
   "metadata": {},
   "outputs": [],
   "source": [
    "rivpts = [Point(i) for i in riv1.coords]\n",
    "# add a starting point and ending point each outside the domain\n",
    "newpt = Point(rivpts[0].coords[0][0],rivpts[0].coords[0][1]+150)\n",
    "rivpts.insert(0,newpt)\n",
    "newpt = Point(rivpts[-1].coords[0][0]+150,rivpts[-1].coords[0][1]-150)\n",
    "rivpts.append(newpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac7feb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rivsegs = []\n",
    "totpts = len(rivpts)/10\n",
    "previous_seg = 0\n",
    "for i in range(1,10):\n",
    "    tmppts = rivpts[previous_seg:int(i*totpts)]\n",
    "    previous_seg = int(i*totpts)-1\n",
    "    rivsegs.append(LineString(zip([c.coords[0][0] for c in tmppts],\n",
    "                                 [c.coords[0][1] for c in tmppts])))\n",
    "tmppts = rivpts[previous_seg:-1]\n",
    "rivsegs.append(LineString(zip([c.coords[0][0] for c in tmppts],\n",
    "                                 [c.coords[0][1] for c in tmppts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ea68bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "riv_divided = gp.GeoDataFrame({'geometry':rivsegs,\n",
    "                               'segname': [i+1+1000 for i in range(len(rivsegs))]},\n",
    "                                                                      crs=riv.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8be491",
   "metadata": {},
   "outputs": [],
   "source": [
    "riv_divided.plot(column='segname', legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffaf6a6",
   "metadata": {},
   "source": [
    "#### now set up routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97addc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "riv_divided ['from_id'] = [i+1000 for i in range(len(riv_divided))]\n",
    "riv_divided.loc[0, 'from_id'] = 0\n",
    "riv_divided ['to_id'] = [i+2+1000 for i in range(len(riv_divided))]\n",
    "riv_divided.loc[9, 'to_id'] = 0\n",
    "# wild guess on river width\n",
    "riv_divided['streamwid'] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16615a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "riv_divided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a1ee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "riv_divided.to_file(datapath / 'shp' / 'River_Lambro_segmented.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae26bfd",
   "metadata": {},
   "source": [
    "## let's take a quick look at the raster data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd656156",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(datapath/ 'raster' / 'DTM_domain.tif') as src:\n",
    "    modtop = src.read(1)\n",
    "plt.imshow(modtop)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aceac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(datapath/ 'raster' / 'Bott_L1_fix.tif') as src:\n",
    "    bot1 = src.read(1)\n",
    "plt.imshow(bot1)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcacc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(datapath/ 'raster' / 'Bott_L2_fix.tif') as src:\n",
    "    bot2 = src.read(1)\n",
    "plt.imshow(bot2)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe4f27a",
   "metadata": {},
   "source": [
    "### we need a raster of the bottom of layer 2 kicked down by 60m to make the bottom of layer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3046f53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open layer 2 again and read the metadata for the raster\n",
    "bot2_rast = rasterio.open(datapath/ 'raster' / 'Bott_L2_fix.tif') \n",
    "meta_lay3 = bot2_rast.meta.copy()\n",
    "meta_lay3.update(compress='lzw') # set compression to be sure file is small as possible\n",
    "bot2_rast.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff6b8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now subtract 60m from layer 2 and write out layer 3\n",
    "bot3 = bot2-60.\n",
    "plt.imshow(bot3)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59294334",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(datapath/ 'raster' / 'Bott_L3_fix.tif', 'w+', **meta_lay3) as ofp:\n",
    "    ofp.write_band(1, bot3)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f3445d",
   "metadata": {},
   "source": [
    "### now a quick check reading back in to make sure that worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b221b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(datapath/ 'raster' / 'Bott_L3_fix.tif') as src:\n",
    "    bot3 = src.read(1)\n",
    "plt.imshow(bot3)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05573cbf",
   "metadata": {},
   "source": [
    "### we need a csv file for the well package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abae0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wells = gp.read_file(datapath / 'shp' / 'wells.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524ea6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = domain.plot(facecolor=\"none\", edgecolor='black')\n",
    "wells.plot( ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e481ba60",
   "metadata": {},
   "outputs": [],
   "source": [
    "wells.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd2378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wells.WellName = wells.WellName.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b35b4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "well_metadata = pd.read_csv(datapath / 'wells_with_elev.dat', index_col=0)\n",
    "well_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac224869",
   "metadata": {},
   "outputs": [],
   "source": [
    "wells.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244e4b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(well_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6436555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#well_metadata = well_metadata.loc[well_metadata.q != 0]\n",
    "len(well_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daca159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "well_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde5415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "well_data = well_metadata.merge(wells[['X','Y','WellName']], left_on='rootname', right_on='WellName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3388614",
   "metadata": {},
   "outputs": [],
   "source": [
    "well_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2e6198",
   "metadata": {},
   "outputs": [],
   "source": [
    "well_data = well_data.rename(columns = {'X':'x', 'Y':'y','laytop':'screen_top','laybot':'screen_botm'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdb2b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to add datetime for pumping\n",
    "well_data['datetime'] = '2021-01-01'\n",
    "well_data['enddatetime'] = '2022-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17fb538",
   "metadata": {},
   "outputs": [],
   "source": [
    "well_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b143467",
   "metadata": {},
   "source": [
    "### Need to add in the barrier well, first have to get the information about top and bottom from the DTM and Layer rasters. Recall that these were read in above as `modtop` and `bot1`, respectively. But, we need to find the indices in row/column coordinates to read the values we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62a695b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are given the coordinates of the barrier well\n",
    "x_barrier, y_barrier = 1519614, 5031870"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc87edb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the coordinates and read the model top and bottom of lay 1 elevations\n",
    "# note that these rasters are at different resolutions, so must read unique coordinates\n",
    "DTM_raster= rasterio.open(datapath/ 'raster' / 'DTM_domain.tif')\n",
    "rDTM,cDTM = DTM_raster.index(x_barrier, y_barrier)\n",
    "DTM_barrier = modtop[rDTM,cDTM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2adc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lay1_raster= rasterio.open(datapath/ 'raster' / 'Bott_L1_fix.tif')\n",
    "rLay1,cLay1 = Lay1_raster.index(x_barrier, y_barrier)\n",
    "bot1_barrier = bot1[rLay1,cLay1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6cf7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rasterio.transform.rowcol(Lay1_raster.transform, x_barrier, y_barrier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b52264",
   "metadata": {},
   "source": [
    "#### drop out the zero pumping (flowing) wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba9cb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "well_no_pumping = well_data.loc[well_data.q == 0].copy()\n",
    "well_no_pumping.loc[:,'screen_botm'] = -300 # set an arbitrarily low elevation for the screen bottom\n",
    "well_no_pumping[['q','x','y',\n",
    "                                 'boundname','screen_top',\n",
    "                                 'screen_botm', 'enddatetime',\n",
    "                                 'datetime','laymidpt']].to_csv(datapath / 'wells_zero.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d71c6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "well_data_2 = well_data.copy()\n",
    "well_data_2.loc[:,'datetime'] = '2022-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fa3699",
   "metadata": {},
   "outputs": [],
   "source": [
    "well_data = pd.concat((well_data,well_data_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d444eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "well_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6fb087",
   "metadata": {},
   "outputs": [],
   "source": [
    "well_data = well_data.append(pd.DataFrame({'cellid':[np.nan],\n",
    "                               'q':[-30/1000],\n",
    "                              'x':[x_barrier],\n",
    "                              'y':[y_barrier],\n",
    "                              'boundname':['barrier'],\n",
    "                              'screen_top':[DTM_barrier],\n",
    "                              'screen_botm':[bot1_barrier],\n",
    "                              'datetime':['2022-01-01'],\n",
    "                              'enddatetime':['2022-12-31'],\n",
    "                              'laymidpt':[np.mean((DTM_barrier, bot1_barrier))],\n",
    "                              'layer':[0],\n",
    "                              'cell':[np.nan],\n",
    "                              'WellName':['barrier']}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb94030",
   "metadata": {},
   "source": [
    "### save out the pumping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c3e505",
   "metadata": {},
   "outputs": [],
   "source": [
    "well_data.loc[well_data.q != 0][['q','x','y',\n",
    "                                 'boundname','screen_top',\n",
    "                                 'screen_botm', 'enddatetime',\n",
    "                                 'datetime','laymidpt']].to_csv(datapath / 'wells_nonzero.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d4ef56",
   "metadata": {},
   "source": [
    "# Now we write the blocks for the model-building YML configuration file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6653bddf",
   "metadata": {},
   "source": [
    "# let's set a lateral discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db00ac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "dxdy = 50 # this value, in meters, controls the lateral resolution of the entire model (what?!?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a6fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the technique at this link to preserve order of the YML output\n",
    "# to make it easier for human readability\n",
    "#https://stackoverflow.com/questions/31605131/dumping-a-dictionary-to-a-yaml-file-while-preserving-order/31609484\n",
    "\n",
    "from collections import OrderedDict\n",
    "def represent_dictionary_order(self, dict_data):\n",
    "    return self.represent_mapping('tag:yaml.org,2002:map', dict_data.items())\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d59143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with an empty dictionary\n",
    "config_data = OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ad59d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make subdictionaries for each section\n",
    "# SIMULATION BLOCK \n",
    "config_data['simulation'] = dict()\n",
    "config_data['simulation']['sim_name'] = f'sgn_{dxdy}_sim'\n",
    "config_data['simulation']['sim_ws'] = '../../models/sgn_mfsetup'\n",
    "config_data['simulation']['version'] = 'mf6'\n",
    "config_data['simulation']['options'] = dict()\n",
    "config_data['simulation']['options']['continue'] = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9944555b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL BLOCK\n",
    "config_data['model'] = dict()\n",
    "config_data['model']['external_path'] = './' \n",
    "config_data['model']['modelname'] = f'sgn_{dxdy}'\n",
    "config_data['model']['relative_external_filepaths'] = True\n",
    "config_data['model']['simulation'] = f'sgn_{dxdy}_sim'\n",
    "\n",
    "# options subblock\n",
    "config_data['model']['options'] = dict()\n",
    "config_data['model']['options']['newton'] = True\n",
    "config_data['model']['options']['newton_under_relaxation'] = True\n",
    "config_data['model']['options']['print_input'] = True\n",
    "config_data['model']['options']['save_flows'] = True\n",
    "# packages block\n",
    "config_data['model']['packages'] = ['dis', 'ims', 'ic', 'wel', 'oc', 'npf', 'rch', 'sfr',\"obs\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5690110",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_data['intermediate_data'] = dict()\n",
    "config_data['intermediate_data']['output_folder'] = 'original/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c11e8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the grid\n",
    "config_data['setup_grid'] = dict()\n",
    "config_data['setup_grid']['epsg'] = domain.crs.to_epsg() # read in from the domain crs\n",
    "config_data['setup_grid']['rotation'] = float(np.round(rot_angle, decimals=5)) # calculated above\n",
    "config_data['setup_grid']['xoff'] = xll # calculated above - lower left corner\n",
    "config_data['setup_grid']['yoff'] = yll # calculated above - lower left corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdffbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the discretization\n",
    "config_data['dis'] = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0489af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dimensions block\n",
    "config_data['dis']['dimensions'] = dict()\n",
    "# from the calcs above and using the specified cell spacing\n",
    "config_data['dis']['dimensions']['ncol'] = int(np.round(width/dxdy) )\n",
    "config_data['dis']['dimensions']['nrow'] = int(np.round(length/dxdy) )\n",
    "config_data['dis']['dimensions']['nlay'] = 3\n",
    "\n",
    "config_data['dis']['drop_thin_cells'] =  True\n",
    "config_data['dis']['minimum_layer_thickness'] = 1.0\n",
    "config_data['dis']['remake_top'] = True\n",
    "\n",
    "config_data['dis']['griddata'] = dict()\n",
    "config_data['dis']['griddata']['delr'] = dxdy\n",
    "config_data['dis']['griddata']['delc'] = dxdy\n",
    "\n",
    "config_data['dis']['options'] = dict()\n",
    "config_data['dis']['options']['length_units'] = 'meters'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c244df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the source data for the dimenstions block above\n",
    "config_data['dis']['source_data'] = dict()\n",
    "config_data['dis']['source_data']['top'] = dict()\n",
    "config_data['dis']['source_data']['top']['filename'] = \\\n",
    "            str(datapath/ 'raster' / 'DTM_domain.tif')\n",
    "config_data['dis']['source_data']['top']['elevation_units'] = 'meters'\n",
    "\n",
    "config_data['dis']['source_data']['botm'] = dict()\n",
    "config_data['dis']['source_data']['botm']['filenames'] = dict()\n",
    "config_data['dis']['source_data']['botm']['filenames'][0] =\\\n",
    "            str(datapath/ 'raster' / 'Bott_L1_fix.tif')\n",
    "config_data['dis']['source_data']['botm']['filenames'][1] =\\\n",
    "            str(datapath/ 'raster' / 'Bott_L2_fix.tif')\n",
    "config_data['dis']['source_data']['botm']['filenames'][2] =\\\n",
    "            str(datapath/ 'raster' / 'Bott_L3_fix.tif')\n",
    "\n",
    "\n",
    "config_data['dis']['source_data']['botm']['elevation_units'] = 'meters'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe8a664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time discretization - simple for steady state\n",
    "config_data['tdis'] = dict()\n",
    "config_data['tdis']['options'] = dict()\n",
    "config_data['tdis']['options']['start_date_time'] = '2021-01-01'\n",
    "config_data['tdis']['options']['time_units'] = 'seconds'\n",
    "config_data['tdis']['perioddata'] = dict()\n",
    "config_data['tdis']['perioddata']['group 1'] = dict()\n",
    "config_data['tdis']['perioddata']['group 1']['nper'] = 1\n",
    "config_data['tdis']['perioddata']['group 1']['perlen'] = 3.154e+7\n",
    "config_data['tdis']['perioddata']['group 1']['nstp'] = 1\n",
    "config_data['tdis']['perioddata']['group 1']['steady'] = True\n",
    "config_data['tdis']['perioddata']['group 1']['tsmult'] = 1\n",
    "config_data['tdis']['perioddata']['group 1']['start_date_time'] = '2021-01-01'\n",
    "config_data['tdis']['perioddata']['group 1']['end_date_time'] = '2021-12-31'\n",
    "\n",
    "config_data['tdis']['perioddata']['group 2'] = dict()\n",
    "config_data['tdis']['perioddata']['group 2'] = dict()\n",
    "config_data['tdis']['perioddata']['group 2']['nper'] = 1\n",
    "config_data['tdis']['perioddata']['group 2']['perlen'] = 3.154e+7\n",
    "config_data['tdis']['perioddata']['group 2']['nstp'] = 1\n",
    "config_data['tdis']['perioddata']['group 2']['steady'] = True\n",
    "config_data['tdis']['perioddata']['group 2']['tsmult'] = 1\n",
    "config_data['tdis']['perioddata']['group 2']['start_date_time'] = '2022-01-01'\n",
    "config_data['tdis']['perioddata']['group 2']['end_date_time'] = '2022-12-31'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66483a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set in initial conditions as top of the model  for now\n",
    "config_data['ic'] = dict()\n",
    "config_data['ic']['strt_filename_fmt'] = \\\n",
    "    str(datapath/ 'raster' / 'DTM_domain.tif')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e99b678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in the wells\n",
    "wellfile = str(datapath / 'wells_nonzero.csv')\n",
    "config_data['wel'] = dict()\n",
    "config_data['wel']['options'] = dict()\n",
    "config_data['wel']['options']['print_input'] = True\n",
    "config_data['wel']['options']['print_flows'] = True\n",
    "config_data['wel']['options']['save_flows'] = True\n",
    "\n",
    "config_data['wel']['source_data'] = dict()\n",
    "config_data['wel']['source_data']['csvfiles'] = dict()\n",
    "\n",
    "config_data['wel']['source_data']['csvfiles']['filenames'] = [wellfile]\n",
    "config_data['wel']['source_data']['csvfiles']['volume_units'] = 'meters'\n",
    "\n",
    "config_data['wel']['source_data']['csvfiles']['time_units'] = 'seconds'\n",
    "config_data['wel']['source_data']['csvfiles']['data_column'] = 'q'\n",
    "config_data['wel']['source_data']['csvfiles']['id_column'] = 'boundname'\n",
    "config_data['wel']['source_data']['csvfiles']['datetime_column'] = 'datetime'\n",
    "config_data['wel']['source_data']['csvfiles']['end_datetime_column'] = 'enddatetime'\n",
    "config_data['wel']['source_data']['csvfiles']['period_stats'] = dict()\n",
    "config_data['wel']['source_data']['csvfiles']['period_stats'][0] = ['mean', '2021-01-01', '2021-12-31']\n",
    "config_data['wel']['source_data']['csvfiles']['period_stats'][1] = ['mean', '2022-01-01', '2022-12-31']\n",
    "\n",
    "\n",
    "\n",
    "config_data['wel']['source_data']['csvfiles']['vertical_flux_distribution'] = dict()\n",
    "config_data['wel']['source_data']['csvfiles']['vertical_flux_distribution']['across_layers'] = False\n",
    "config_data['wel']['source_data']['csvfiles']['vertical_flux_distribution']['distribute_by'] = 'transmissivity'\n",
    "config_data['wel']['source_data']['csvfiles']['vertical_flux_distribution']['screen_top_col'] = 'screen_top'\n",
    "config_data['wel']['source_data']['csvfiles']['vertical_flux_distribution']['screen_botm_col'] = 'screen_botm'\n",
    "config_data['wel']['source_data']['csvfiles']['vertical_flux_distribution']['screen_botm_col'] = 'screen_botm'\n",
    "\n",
    "#config_data['wel']['source_data']['csvfiles']['vertical_flux_distribution']['minimum_layer_thickess'] = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74881bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output control\n",
    "config_data['oc'] = dict()\n",
    "config_data['oc']['budget_fileout_fmt'] = '{}.cbc'\n",
    "config_data['oc']['head_fileout_fmt'] = '{}.hds'\n",
    "config_data['oc']['saverecord'] = dict()\n",
    "config_data['oc']['saverecord'][0] = dict()\n",
    "\n",
    "config_data['oc']['saverecord'][0]['budget'] = 'last'\n",
    "config_data['oc']['saverecord'][0]['head'] = 'last'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b07749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#node property flow\n",
    "geology_file = str(datapath / 'raster' / 'k_field{}.tif')\n",
    "config_data['npf'] = dict()\n",
    "config_data['npf']['source_data'] = dict()\n",
    "config_data['npf']['source_data']['k'] = dict()\n",
    "\n",
    "config_data['npf']['source_data']['k']['filenames'] = dict()\n",
    "config_data['npf']['source_data']['k']['filenames'][0] = geology_file.format(0)\n",
    "config_data['npf']['source_data']['k']['filenames'][1] = geology_file.format(1)\n",
    "config_data['npf']['source_data']['k']['filenames'][2] = geology_file.format(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55fb5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recharge\n",
    "rch_file = str(datapath / 'raster' / 'rch.tif')\n",
    "config_data['rch'] = dict()\n",
    "config_data['rch']['options'] = dict()\n",
    "config_data['rch']['options']['print_output'] = True\n",
    "config_data['rch']['options']['print_flows'] = False\n",
    "config_data['rch']['options']['save_flows'] = True\n",
    "config_data['rch']['options']['readasarrays'] = True\n",
    "config_data['rch']['source_data'] = dict()\n",
    "config_data['rch']['source_data']['recharge'] = dict()\n",
    "config_data['rch']['source_data']['recharge']['filenames'] = dict()\n",
    "config_data['rch']['source_data']['recharge']['filenames'][0] = rch_file\n",
    "config_data['rch']['source_data']['recharge']['length_units'] = 'millimeters'\n",
    "config_data['rch']['source_data']['recharge']['time_units'] = 'years'\n",
    "config_data['rch']['source_data']['recharge']['period_stats'] = dict()\n",
    "config_data['rch']['source_data']['recharge']['period_stats'][0] = 'mean'\n",
    "config_data['rch']['source_data']['recharge']['period_stats'][1] = 'mean'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9553f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# streamflow routing\n",
    "rivfile = str(datapath / 'shp' / 'River_Lambro_segmented.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9e55e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for SFR observations, we need to make a CSV file with the segments identified\n",
    "inriv = gp.read_file(rivfile)\n",
    "inriv['obsname'] = [f'seg_{i}' for i in inriv.segname]\n",
    "inriv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0efd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "rivsegfile = str(datapath / 'csv' / 'river_segments.csv')\n",
    "inriv[['segname', 'obsname']].to_csv(rivsegfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841a61a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_data['sfr'] = dict()\n",
    "config_data['sfr']['source_data'] = dict()\n",
    "config_data['sfr']['source_data']['flowlines'] = dict()\n",
    "config_data['sfr']['source_data']['flowlines']['filename'] = rivfile\n",
    "config_data['sfr']['source_data']['flowlines']['id_column'] = 'segname'\n",
    "config_data['sfr']['source_data']['flowlines']['routing_column'] = 'to_id'\n",
    "config_data['sfr']['source_data']['flowlines']['width1'] = 'streamwid'\n",
    "config_data['sfr']['source_data']['flowlines']['width2'] = 'streamwid'\n",
    "\n",
    "\n",
    "config_data['sfr']['source_data']['dem'] = dict()\n",
    "config_data['sfr']['source_data']['dem']['filename'] = \\\n",
    "         str(datapath/ 'raster' / 'DTM_domain.tif')\n",
    "config_data['sfr']['source_data']['dem']['elevation_units'] = 'meters'\n",
    "\n",
    "config_data['sfr']['source_data']['observations'] = dict()\n",
    "config_data['sfr']['source_data']['observations']['filename'] = rivsegfile\n",
    "config_data['sfr']['source_data']['observations']['obstype'] = ['sfr','outflow', 'downstream-flow','ext-outflow']\n",
    "config_data['sfr']['source_data']['observations']['line_id_column'] = 'segname'\n",
    "config_data['sfr']['source_data']['observations']['obsname_column'] = 'obsname'\n",
    "\n",
    "config_data['sfr']['set_streambed_top_elevations_from_dem'] = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425bc8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver settings\n",
    "config_data['ims'] = dict()\n",
    "config_data['ims']['options'] = dict()\n",
    "config_data['ims']['options']['print_options'] = 'all'\n",
    "config_data['ims']['options']['complexity'] = 'moderate'\n",
    "config_data['ims']['nonlinear'] = dict()\n",
    "config_data['ims']['nonlinear']['outer_dvclose'] = 0.01\n",
    "config_data['ims']['linear'] = dict()\n",
    "config_data['ims']['linear']['inner_dvclose'] = 0.00001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3e3314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in head observations\n",
    "config_data['obs'] = dict()\n",
    "config_data['obs']['source_data'] = dict()\n",
    "config_data['obs']['source_data']['filenames'] = '../../data/sgn/csv/heads_sep2019.csv'\n",
    "config_data['obs']['source_data']['column_mappings'] = dict()\n",
    "\n",
    "config_data['obs']['source_data']['column_mappings']['obsname'] = 'ID'\n",
    "config_data['obs']['source_data']['column_mappings']['x'] = 'X'\n",
    "config_data['obs']['source_data']['column_mappings']['y'] = 'Y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cce203",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml.add_representer(OrderedDict, represent_dictionary_order)\n",
    "with open('sgn_config.yml', 'w') as outfile:\n",
    "    yaml.dump(config_data, outfile, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0776997",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
