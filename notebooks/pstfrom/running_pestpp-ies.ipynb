{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3adc405c",
   "metadata": {},
   "source": [
    "# Running `PESTPP-IES`\n",
    "\n",
    "In this notebook we will use the pest interface that we constructed and tested in the previous notebooks to do prior and posterior parameter and forecast non-linear uncertainty analysis! exciting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2069460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "sys.path.append('../../dependencies/')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "font = {'size'   : 12}\n",
    "mpl.rc('font', **font)\n",
    "import flopy as fp\n",
    "import pyemu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e08ccbe",
   "metadata": {},
   "source": [
    "First let's make sure the previous steps have been completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a68ab6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mname = \"sgn_50\"\n",
    "t_d = os.path.join(\"..\",\"..\",\"models\",\"template\")\n",
    "assert os.path.exists(t_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a0c3097",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(t_d,\"sgn.pst\"))\n",
    "assert pst.nobs != pst.nnz_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19061cd7",
   "metadata": {},
   "source": [
    "A critical first step in any predictive modeling analysis is a simple Monte Carlo analysis.  While simple in concept, this analysis provides incredible insights for many aspects of the modeling analysis, including clues about model stability (or otherwise), prior-data conflict, and, if the outputs of interest are included as \"observations\" in the control file (as they are in this case), then you also get Prior predictive uncertainty!\n",
    "\n",
    "Mechanically, if you set `noptmax=-1`, this tell PESTPP-IES to evaluate the initial (e.g. prior) parameter ensemble and quit. easy as!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb4aef32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noptmax:-1, npar_adj:69143, nnz_obs:90\n"
     ]
    }
   ],
   "source": [
    "pst.control_data.noptmax = -1\n",
    "pst.pestpp_options[\"save_binary\"] = True\n",
    "pst.write(os.path.join(t_d,\"sgn.pst\"),version=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d711c8",
   "metadata": {},
   "source": [
    "Here we will use a pyemu helper function to start PESTPP-IES parallel mode so that we have a master instance and several workers.  The master coordinates the runs that need to be done and the workers just work...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aead12ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_root = os.path.join(\"..\",\"..\",\"models\")\n",
    "pmc_m_d = os.path.join(worker_root,\"master_prior_mc\")\n",
    "pyemu.os_utils.start_workers(t_d,\"pestpp-ies\",\"sgn.pst\",num_workers=10,\n",
    "                             master_dir=pmc_m_d,worker_root=worker_root,\n",
    "                            port=4269)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1e4130",
   "metadata": {},
   "source": [
    "Sweet!  Now we are in a position to plot the prior monte carlo results.  First, let's compare the simulated outputs to the observed values.  In this case, PESTPP-IES creates an \"obs+noise\" ensemble that, as the name suggests, is an observation ensemble of obseration values with unique, additive observation noise realizations (the observation standard deviation is taken as the inverse of the observation weight unless otherwise specified).  Conceptually, this means that the posterior PESTPP-IES result will account for both parameter and observation noise uncertainty!  \n",
    "\n",
    "Below we will plot each obs+noise PDF with the corresponding simulated PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45f8bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cols = pst.observation_data.loc[pst.nnz_obs_names].apply(lambda x: x.usecol + \" \"+x.oname,axis=1).to_dict()\n",
    "plot_cols = {v: [k] for k, v in plot_cols.items()}\n",
    "pyemu.plot_utils.ensemble_helper({\"r\":os.path.join(pmc_m_d,\"sgn.obs+noise.jcb\"),\n",
    "                                  \"0.5\":os.path.join(pmc_m_d,\"sgn.0.obs.jcb\")},\n",
    "                                 plot_cols=plot_cols,bins=20,sync_bins=False,\n",
    "                                func_dict={o:lambda x: np.log10(x) for o in pst.nnz_obs_names if \"conc\" in o},\n",
    "                                density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3b46dd",
   "metadata": {},
   "source": [
    "Any thoughts on these plots?  Any plot where the prior simulated PDF doesnt statistically cover the obs+noise PDF is a problem..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6029b2d1",
   "metadata": {},
   "source": [
    "OK! Now we are ready for some (attempted) history matching.  Let's use 4 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06bacc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noptm = 4\n",
    "pst.control_data.noptmax = noptm\n",
    "pst.pestpp_options[\"ies_no_noise\"] = False\n",
    "pst.write(os.path.join(t_d,\"sgn.pst\"),version=2)\n",
    "ies_m_d = os.path.join(worker_root,\"master_ies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb6a5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.start_workers(t_d,\"pestpp-ies\",\"sgn.pst\",num_workers=10,\n",
    "                             master_dir=ies_m_d,worker_root=worker_root,port=4269)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c09d711",
   "metadata": {},
   "source": [
    "Sweet!  Let's take a peek at the phi summary information from `pestpp-ies`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a846f8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(ies_m_d,\"sgn.phi.actual.csv\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db01994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1)\n",
    "_ = [ax.plot(df.total_runs,np.log10(df.loc[:,i].values),\"0.5\",lw=0.5) for i in df.columns[5:]]\n",
    "ax.set_ylabel(\"$log_{10}\\\\phi$\")\n",
    "ax.set_xlabel(\"model runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e9c22",
   "metadata": {},
   "source": [
    "Now let's plot up the observations plus noise, the prior simulated values, and the posterior simulated values. first lets load up the prior and posterior observation ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723d741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pr_oe = pd.read_csv(os.path.join(ies_m_d,\"sgn.0.obs.csv\"),index_col=0)\n",
    "#pt_oe = pd.read_csv(os.path.join(ies_m_d,\"sgn.{0}.obs.csv\".format(noptm)),index_col=0)\n",
    "\n",
    "pr_oe = pyemu.ObservationEnsemble.from_binary(pst=pst,filename=os.path.join(ies_m_d,\"sgn.0.obs.jcb\"))\n",
    "pt_oe = pyemu.ObservationEnsemble.from_binary(pst=pst,filename=os.path.join(ies_m_d,\"sgn.{0}.obs.jcb\".format(noptm)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfab54d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_cols = pst.observation_data.loc[pst.nnz_obs_names].apply(lambda x: x.usecol + \" \"+x.oname,axis=1).to_dict()\n",
    "plot_cols = {v: [k] for k, v in plot_cols.items()}\n",
    "pyemu.plot_utils.ensemble_helper({\"r\":os.path.join(ies_m_d,\"sgn.obs+noise.csv\"),\n",
    "                                  \"0.5\":pr_oe,\"b\":pt_oe},\n",
    "                                  plot_cols=plot_cols,bins=20,sync_bins=False,\n",
    "                                  func_dict={o:lambda x: np.log10(x) for o in pst.nnz_obs_names if \"conc\" in o})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abec717",
   "metadata": {},
   "source": [
    "Now lets plot up some head and concentration maps- always fun! Remember when we added observations for the simulated head and concentration in all model cells? here is where that pays off!  Here we will get pieces of the `pyemu.Pst.observation_data` dataframe that are for the layer head and concentrations of interest.  We can use `lay1_hds`/`lay1_ucn`, `lay2_hds`/`lay2_ucn` or `lay3_hds`/`lay3_ucn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401f5e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "otag = \"lay1\"\n",
    "otime = 1\n",
    "obs = pst.observation_data\n",
    "h_tag = \"{0}__t{1}_hds\".format(otag,otime)\n",
    "c_tag = \"{0}_t{1}_ucn\".format(otag,otime)\n",
    "\n",
    "print(h_tag,c_tag)\n",
    "\n",
    "lay_hobs = obs.loc[obs.obsnme.str.contains(h_tag),:].copy()\n",
    "assert lay_hobs.shape[0] > 0\n",
    "lay_cobs = obs.loc[obs.obsnme.str.contains(c_tag),:].copy()\n",
    "assert lay_cobs.shape[0] > 0\n",
    "lay_hobs.loc[:,\"i\"] = lay_hobs.i.astype(int)\n",
    "lay_cobs.loc[:,\"i\"] = lay_cobs.i.astype(int)\n",
    "lay_hobs.loc[:,\"j\"] = lay_hobs.j.astype(int)\n",
    "lay_cobs.loc[:,\"j\"] = lay_cobs.j.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f062107",
   "metadata": {},
   "source": [
    "Let's just plot a few realizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f8d4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reals = pr_oe.index[:4].tolist()\n",
    "reals.append(\"base\")\n",
    "reals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db952bd2",
   "metadata": {},
   "source": [
    "Below, we just work out the min and max concentration and head values so that the plots are coherent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d86adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmn = pt_oe.loc[reals,lay_cobs.obsnme].min().min()\n",
    "cmx = pt_oe.loc[reals,lay_cobs.obsnme].max().max()\n",
    "hmn = pt_oe.loc[reals,lay_hobs.obsnme].min().min()\n",
    "hmx = pt_oe.loc[reals,lay_hobs.obsnme].max().max()\n",
    "hlevels = np.linspace(hmn,hmx,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024ad613",
   "metadata": {},
   "source": [
    "Now for some matplotlib hackery! For each realization, we will instantiate an empty numpy array and then fill it with the realization values. Then plot and add some nice things..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a333a51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lay_hobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97c466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for real in reals:\n",
    "    pr_harr = np.zeros((lay_hobs.i.max()+1,lay_hobs.j.max()+1))\n",
    "    pr_harr[lay_hobs.i,lay_hobs.j] = pr_oe.loc[real,lay_hobs.obsnme]\n",
    "    pr_carr = np.zeros((lay_cobs.i.max()+1,lay_cobs.j.max()+1))\n",
    "    pr_carr[lay_cobs.i,lay_cobs.j] = pr_oe.loc[real,lay_cobs.obsnme]\n",
    "    \n",
    "    pt_harr = np.zeros((lay_hobs.i.max()+1,lay_hobs.j.max()+1))\n",
    "    pt_harr[lay_hobs.i,lay_hobs.j] = pt_oe.loc[real,lay_hobs.obsnme]\n",
    "    pt_carr = np.zeros((lay_cobs.i.max()+1,lay_cobs.j.max()+1))\n",
    "    pt_carr[lay_cobs.i,lay_cobs.j] = pt_oe.loc[real,lay_cobs.obsnme]\n",
    "\n",
    "    pr_carr[pr_carr<0.001] = np.nan\n",
    "    pt_carr[pt_carr<0.001] = np.nan\n",
    "    \n",
    "\n",
    "    fig,axes = plt.subplots(1,2,figsize=(12,5))\n",
    "    axes[0].imshow(pr_carr,vmin=cmn,vmax=cmx)\n",
    "    cb = axes[1].imshow(pt_carr,vmin=cmn,vmax=cmx)\n",
    "    plt.colorbar(cb,ax=axes[1])\n",
    "    \n",
    "    cs = axes[0].contour(pr_harr,levels=hlevels,colors=\"0.5\")\n",
    "    axes[0].clabel(cs)\n",
    "    cs = axes[1].contour(pt_harr,levels=hlevels,colors=\"0.5\")\n",
    "    axes[1].clabel(cs)\n",
    "    axes[0].set_title(\"{0} prior realization {1}\".format(tag,real))\n",
    "    axes[1].set_title(\"{0} posterior realization {1}\".format(tag,real))\n",
    "    \n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8699c2",
   "metadata": {},
   "source": [
    "For each realization, we see extreme concentration values in the prior, as we should since the prior represents expert knowledge only and no detailed aquifer-specific information that is contained in the observations.  But the posterior realizations are more tame after conditioning the parameters on those aquifer-specific data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768d5992",
   "metadata": {},
   "source": [
    "Now let's run PESTPP-IES again but this time without using concentration observations.  This will give us a measure of how important those concentration observations are for reducing predictive uncertainty..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0df40fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_nnz_obs = [o for o in pst.nnz_obs_names if \"conc\" in o]\n",
    "pst.observation_data.loc[conc_nnz_obs,\"weight\"] = 0\n",
    "pst.write(os.path.join(t_d,\"sgn.pst\"),version=2)\n",
    "ies_m_d_ho = os.path.join(worker_root,\"master_ies_headonly\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf42fa5",
   "metadata": {},
   "source": [
    "From here on, this is exactly the same code used above..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbbcb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.start_workers(t_d,\"pestpp-ies\",\"sgn.pst\",num_workers=10,\n",
    "                             master_dir=ies_m_d_ho,worker_root=worker_root,port=4269)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76ec54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_oe_ho = pyemu.ObservationEnsemble.from_binary(pst=pst,filename=os.path.join(ies_m_d_ho,\"sgn.0.obs.jcb\"))\n",
    "pt_oe_ho = pyemu.ObservationEnsemble.from_binary(pst=pst,filename=os.path.join(ies_m_d_ho,\"sgn.{0}.obs.jcb\".format(noptm)))\n",
    "reals_ho = pr_oe_ho.index[:4].tolist()\n",
    "reals_ho.append(\"base\")\n",
    "reals_ho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa9281",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmn = pt_oe_ho.loc[reals_ho,lay_cobs.obsnme].min().min()\n",
    "cmx = pt_oe_ho.loc[reals_ho,lay_cobs.obsnme].max().max()\n",
    "hmn = pt_oe_ho.loc[reals_ho,lay_hobs.obsnme].min().min()\n",
    "hmx = pt_oe_ho.loc[reals_ho,lay_hobs.obsnme].max().max()\n",
    "hlevels = np.linspace(hmn,hmx,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcc939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for real in reals_ho:\n",
    "    pr_harr = np.zeros((lay_hobs.i.max()+1,lay_hobs.j.max()+1))\n",
    "    pr_harr[lay_hobs.i,lay_hobs.j] = pr_oe_ho.loc[real,lay_hobs.obsnme]\n",
    "    pr_carr = np.zeros((lay_cobs.i.max()+1,lay_cobs.j.max()+1))\n",
    "    pr_carr[lay_cobs.i,lay_cobs.j] = pr_oe_ho.loc[real,lay_cobs.obsnme]\n",
    "    \n",
    "    pt_harr = np.zeros((lay_hobs.i.max()+1,lay_hobs.j.max()+1))\n",
    "    pt_harr[lay_hobs.i,lay_hobs.j] = pt_oe_ho.loc[real,lay_hobs.obsnme]\n",
    "    pt_carr = np.zeros((lay_cobs.i.max()+1,lay_cobs.j.max()+1))\n",
    "    pt_carr[lay_cobs.i,lay_cobs.j] = pt_oe_ho.loc[real,lay_cobs.obsnme]\n",
    "\n",
    "    pr_carr[pr_carr<0.001] = np.nan\n",
    "    pt_carr[pt_carr<0.001] = np.nan\n",
    "    \n",
    "\n",
    "    fig,axes = plt.subplots(1,2,figsize=(12,5))\n",
    "    axes[0].imshow(pr_carr,vmin=cmn,vmax=cmx)\n",
    "    cb = axes[1].imshow(pt_carr,vmin=cmn,vmax=cmx)\n",
    "    plt.colorbar(cb,ax=axes[1])\n",
    "    \n",
    "    cs = axes[0].contour(pr_harr,levels=hlevels,colors=\"0.5\")\n",
    "    axes[0].clabel(cs)\n",
    "    cs = axes[1].contour(pt_harr,levels=hlevels,colors=\"0.5\")\n",
    "    axes[1].clabel(cs)\n",
    "    axes[0].set_title(\"{0} prior realization {1}\".format(tag,real))\n",
    "    axes[1].set_title(\"{0} posterior realization {1}\".format(tag,real))\n",
    "    \n",
    "    \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
