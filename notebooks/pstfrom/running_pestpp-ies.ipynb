{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3adc405c",
   "metadata": {},
   "source": [
    "# Running `PESTPP-IES`\n",
    "\n",
    "In this notebook we will use the pest interface that we constructed and tested in the previous notebooks to do prior and posterior parameter and forecast non-linear uncertainty analysis! exciting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2069460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "sys.path.append('../../dependencies/')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "font = {'size'   : 12}\n",
    "mpl.rc('font', **font)\n",
    "import flopy as fp\n",
    "import pyemu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f99f56",
   "metadata": {},
   "source": [
    "First let's make sure the previous steps have been completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68ab6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mname = \"sgn_50\"\n",
    "t_d = os.path.join(\"..\",\"..\",\"models\",\"template\")\n",
    "assert os.path.exists(t_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0c3097",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(t_d,\"sgn.pst\"))\n",
    "assert pst.nobs != pst.nnz_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1204ee1",
   "metadata": {},
   "source": [
    "A critical first step in any predictive modeling analysis is a simple Monte Carlo analysis.  While simple in concept, this analysis provides incredible insights for many aspects of the modeling analysis, including clues about model stability (or otherwise), prior-data conflict, and, if the outputs of interest are included as \"observations\" in the control file (as they are in this case), then you also get Prior predictive uncertainty!\n",
    "\n",
    "Mechanically, if you set `noptmax=-1`, this tell PESTPP-IES to evaluate the initial (e.g. prior) parameter ensemble and quit. easy as!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4aef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.control_data.noptmax = -1\n",
    "pst.pestpp_options[\"save_binary\"] = True\n",
    "pst.write(os.path.join(t_d,\"sgn.pst\"),version=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c37be4",
   "metadata": {},
   "source": [
    "Here we will use a pyemu helper function to start PESTPP-IES parallel mode so that we have a master instance and several workers.  The master coordinates the runs that need to be done and the workers just work....\n",
    "\n",
    "VERY IMPORTANT:  the `num_worker` argument needs to be set with respect to the computational power of your machine.  If you have a beefy workstation, then 10 is reasonable.  If you a simple laptop, you probably need to use 4 or 5.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aead12ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_root = os.path.join(\"..\",\"..\",\"models\")\n",
    "pmc_m_d = os.path.join(worker_root,\"master_prior_mc\")\n",
    "pyemu.os_utils.start_workers(t_d,\"pestpp-ies\",\"sgn.pst\",num_workers=10,\n",
    "                             master_dir=pmc_m_d,worker_root=worker_root,\n",
    "                            port=4269)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e189b5f",
   "metadata": {},
   "source": [
    "Sweet!  Now we are in a position to plot the prior monte carlo results.  First, let's compare the simulated outputs to the observed values.  In this case, PESTPP-IES creates an \"obs+noise\" ensemble that, as the name suggests, is an observation ensemble of obseration values with unique, additive observation noise realizations (the observation standard deviation is taken as the inverse of the observation weight unless otherwise specified).  Conceptually, this means that the posterior PESTPP-IES result will account for both parameter and observation noise uncertainty!  \n",
    "\n",
    "Below we will plot each obs+noise PDF with the corresponding simulated PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45f8bab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_cols = pst.observation_data.loc[pst.nnz_obs_names].apply(lambda x: x.usecol + \" \"+x.oname,axis=1).to_dict()\n",
    "plot_cols = {v: [k] for k, v in plot_cols.items()}\n",
    "obs_plus_noise = pyemu.ObservationEnsemble.from_binary(pst=pst,filename=os.path.join(pmc_m_d,\"sgn.obs+noise.jcb\"))\n",
    "pr_oe = pyemu.ObservationEnsemble.from_binary(pst=pst,filename=os.path.join(pmc_m_d,\"sgn.0.obs.jcb\"))\n",
    "pyemu.plot_utils.ensemble_helper({\"r\":obs_plus_noise,\"0.5\":pr_oe},\n",
    "                                 plot_cols=plot_cols,bins=20,sync_bins=False,\n",
    "                                func_dict={o:lambda x: np.log10(x) for o in pst.nnz_obs_names if \"conc\" in o},\n",
    "                                density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a9baf3",
   "metadata": {},
   "source": [
    "Any thoughts on these plots?  Any plot where the prior simulated PDF doesnt statistically cover the obs+noise PDF is a problem..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e8807c",
   "metadata": {},
   "source": [
    "OK! Now we are ready for some (attempted) history matching.  Let's use 2 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06bacc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noptm = 2\n",
    "pst.control_data.noptmax = noptm\n",
    "pst.pestpp_options[\"ies_no_noise\"] = False\n",
    "pst.write(os.path.join(t_d,\"sgn.pst\"),version=2)\n",
    "ies_m_d = os.path.join(worker_root,\"master_ies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1877a51",
   "metadata": {},
   "source": [
    "VERY IMPORTANT:  the `num_worker` argument needs to be set with respect to the computational power of your machine.  If you have a beefy workstation, then 10 is reasonable.  If you a simple laptop, you probably need to use 4 or 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb6a5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.start_workers(t_d,\"pestpp-ies\",\"sgn.pst\",num_workers=10,\n",
    "                             master_dir=ies_m_d,worker_root=worker_root,port=4269)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c09d711",
   "metadata": {},
   "source": [
    "Sweet!  Let's take a peek at the phi summary information from `pestpp-ies`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a846f8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(ies_m_d,\"sgn.phi.actual.csv\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db01994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1)\n",
    "_ = [ax.plot(df.total_runs,np.log10(df.loc[:,i].values),\"0.5\",lw=0.5) for i in df.columns[5:]]\n",
    "ax.set_ylabel(\"$log_{10}\\\\phi$\")\n",
    "ax.set_xlabel(\"model runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e9c22",
   "metadata": {},
   "source": [
    "Now let's plot up the observations plus noise, the prior simulated values, and the posterior simulated values. first lets load up the prior and posterior observation ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723d741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pr_oe = pd.read_csv(os.path.join(ies_m_d,\"sgn.0.obs.csv\"),index_col=0)\n",
    "#pt_oe = pd.read_csv(os.path.join(ies_m_d,\"sgn.{0}.obs.csv\".format(noptm)),index_col=0)\n",
    "\n",
    "pr_oe = pyemu.ObservationEnsemble.from_binary(pst=pst,filename=os.path.join(ies_m_d,\"sgn.0.obs.jcb\"))\n",
    "pt_oe = pyemu.ObservationEnsemble.from_binary(pst=pst,filename=os.path.join(ies_m_d,\"sgn.{0}.obs.jcb\".format(noptm)))\n",
    "obs_plus_noise = pyemu.ObservationEnsemble.from_binary(pst=pst,filename=os.path.join(ies_m_d,\"sgn.obs+noise.jcb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfab54d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_cols = pst.observation_data.loc[pst.nnz_obs_names].apply(lambda x: x.usecol + \" \"+x.oname,axis=1).to_dict()\n",
    "plot_cols = {v: [k] for k, v in plot_cols.items()}\n",
    "pyemu.plot_utils.ensemble_helper({\"r\":obs_plus_noise,\"0.5\":pr_oe,\"b\":pt_oe},\n",
    "                                  plot_cols=plot_cols,bins=20,sync_bins=False,\n",
    "                                  func_dict={o:lambda x: np.log10(x) for o in pst.nnz_obs_names if \"conc\" in o})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abec717",
   "metadata": {},
   "source": [
    "Now lets plot up some head and concentration maps- always fun! Remember when we added observations for the simulated head and concentration in all model cells? here is where that pays off!  Here we will get pieces of the `pyemu.Pst.observation_data` dataframe that are for the layer head and concentrations of interest.  We can use `lay1_hds`/`lay1_ucn`, `lay2_hds`/`lay2_ucn` or `lay3_hds`/`lay3_ucn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401f5e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "otag = \"lay1\"\n",
    "otime = 1\n",
    "obs = pst.observation_data\n",
    "h_tag = \"{0}__t{1}_hds\".format(otag,otime)\n",
    "c_tag = \"{0}_t{1}_ucn\".format(otag,otime)\n",
    "\n",
    "print(h_tag,c_tag)\n",
    "\n",
    "lay_hobs = obs.loc[obs.obsnme.str.contains(h_tag),:].copy()\n",
    "assert lay_hobs.shape[0] > 0\n",
    "lay_cobs = obs.loc[obs.obsnme.str.contains(c_tag),:].copy()\n",
    "assert lay_cobs.shape[0] > 0\n",
    "lay_hobs.loc[:,\"i\"] = lay_hobs.i.astype(int)\n",
    "lay_cobs.loc[:,\"i\"] = lay_cobs.i.astype(int)\n",
    "lay_hobs.loc[:,\"j\"] = lay_hobs.j.astype(int)\n",
    "lay_cobs.loc[:,\"j\"] = lay_cobs.j.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f062107",
   "metadata": {},
   "source": [
    "Let's just plot a few realizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f8d4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reals = pt_oe.index[:4].tolist()\n",
    "if \"base\" not in reals:\n",
    "    reals.append(\"base\")\n",
    "reals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db952bd2",
   "metadata": {},
   "source": [
    "Below, we just work out the min and max concentration and head values so that the plots are coherent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d86adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmn = pt_oe.loc[reals,lay_cobs.obsnme].min().min()\n",
    "cmx = pt_oe.loc[reals,lay_cobs.obsnme].max().max()\n",
    "hmn = pt_oe.loc[reals,lay_hobs.obsnme].min().min()\n",
    "hmx = pt_oe.loc[reals,lay_hobs.obsnme].max().max()\n",
    "hlevels = np.linspace(hmn,hmx,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024ad613",
   "metadata": {},
   "source": [
    "Now for some matplotlib hackery! For each realization, we will instantiate an empty numpy array and then fill it with the realization values. Then plot and add some nice things..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a333a51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lay_hobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97c466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for real in reals:\n",
    "    pr_harr = np.zeros((lay_hobs.i.max()+1,lay_hobs.j.max()+1))\n",
    "    pr_harr[lay_hobs.i,lay_hobs.j] = pr_oe.loc[real,lay_hobs.obsnme]\n",
    "    pr_carr = np.zeros((lay_cobs.i.max()+1,lay_cobs.j.max()+1))\n",
    "    pr_carr[lay_cobs.i,lay_cobs.j] = pr_oe.loc[real,lay_cobs.obsnme]\n",
    "    \n",
    "    pt_harr = np.zeros((lay_hobs.i.max()+1,lay_hobs.j.max()+1))\n",
    "    pt_harr[lay_hobs.i,lay_hobs.j] = pt_oe.loc[real,lay_hobs.obsnme]\n",
    "    pt_carr = np.zeros((lay_cobs.i.max()+1,lay_cobs.j.max()+1))\n",
    "    pt_carr[lay_cobs.i,lay_cobs.j] = pt_oe.loc[real,lay_cobs.obsnme]\n",
    "\n",
    "    pr_carr[pr_carr<0.001] = np.nan\n",
    "    pt_carr[pt_carr<0.001] = np.nan\n",
    "    \n",
    "\n",
    "    fig,axes = plt.subplots(1,2,figsize=(12,5))\n",
    "    axes[0].imshow(pr_carr,vmin=cmn,vmax=cmx)\n",
    "    cb = axes[1].imshow(pt_carr,vmin=cmn,vmax=cmx)\n",
    "    plt.colorbar(cb,ax=axes[1])\n",
    "    \n",
    "    cs = axes[0].contour(pr_harr,levels=hlevels,colors=\"0.5\")\n",
    "    axes[0].clabel(cs)\n",
    "    cs = axes[1].contour(pt_harr,levels=hlevels,colors=\"0.5\")\n",
    "    axes[1].clabel(cs)\n",
    "    axes[0].set_title(\"{0} prior realization {1}\".format(otag,real))\n",
    "    axes[1].set_title(\"{0} posterior realization {1}\".format(otag,real))\n",
    "    \n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8699c2",
   "metadata": {},
   "source": [
    "For each realization, we see extreme concentration values in the prior, as we should since the prior represents expert knowledge only and no detailed aquifer-specific information that is contained in the observations.  But the posterior realizations are more tame after conditioning the parameters on those aquifer-specific data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614bcb33",
   "metadata": {},
   "source": [
    "Now let's run PESTPP-IES again but this time without using concentration observations.  This will give us a measure of how important those concentration observations are for reducing predictive uncertainty..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0df40fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_nnz_obs = [o for o in pst.nnz_obs_names if \"conc\" in o]\n",
    "pst.observation_data.loc[conc_nnz_obs,\"weight\"] = 0\n",
    "pst.write(os.path.join(t_d,\"sgn.pst\"),version=2)\n",
    "ies_m_d_ho = os.path.join(worker_root,\"master_ies_headonly\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5dcec5",
   "metadata": {},
   "source": [
    "From here on, this is exactly the same code used above...\n",
    "\n",
    "VERY IMPORTANT:  the `num_worker` argument needs to be set with respect to the computational power of your machine.  If you have a beefy workstation, then 10 is reasonable.  If you a simple laptop, you probably need to use 4 or 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.start_workers(t_d,\"pestpp-ies\",\"sgn.pst\",num_workers=10,\n",
    "                             master_dir=ies_m_d_ho,worker_root=worker_root,port=4269)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09262d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_oe_ho = pyemu.ObservationEnsemble.from_binary(pst=pst,filename=os.path.join(ies_m_d_ho,\"sgn.0.obs.jcb\"))\n",
    "pt_oe_ho = pyemu.ObservationEnsemble.from_binary(pst=pst,filename=os.path.join(ies_m_d_ho,\"sgn.{0}.obs.jcb\".format(noptm)))\n",
    "obs_plus_noise = pyemu.ObservationEnsemble.from_binary(pst=pst,filename=os.path.join(ies_m_d_ho,\"sgn.obs+noise.jcb\"))\n",
    "\n",
    "reals_ho = pt_oe_ho.index[:4].tolist()\n",
    "reals_ho.append(\"base\")\n",
    "reals_ho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1739d61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmn = pt_oe_ho.loc[reals_ho,lay_cobs.obsnme].min().min()\n",
    "cmx = pt_oe_ho.loc[reals_ho,lay_cobs.obsnme].max().max()\n",
    "hmn = pt_oe_ho.loc[reals_ho,lay_hobs.obsnme].min().min()\n",
    "hmx = pt_oe_ho.loc[reals_ho,lay_hobs.obsnme].max().max()\n",
    "hlevels = np.linspace(hmn,hmx,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7100543",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for real in reals_ho:\n",
    "    pr_harr = np.zeros((lay_hobs.i.max()+1,lay_hobs.j.max()+1))\n",
    "    pr_harr[lay_hobs.i,lay_hobs.j] = pr_oe_ho.loc[real,lay_hobs.obsnme]\n",
    "    pr_carr = np.zeros((lay_cobs.i.max()+1,lay_cobs.j.max()+1))\n",
    "    pr_carr[lay_cobs.i,lay_cobs.j] = pr_oe_ho.loc[real,lay_cobs.obsnme]\n",
    "    \n",
    "    pt_harr = np.zeros((lay_hobs.i.max()+1,lay_hobs.j.max()+1))\n",
    "    pt_harr[lay_hobs.i,lay_hobs.j] = pt_oe_ho.loc[real,lay_hobs.obsnme]\n",
    "    pt_carr = np.zeros((lay_cobs.i.max()+1,lay_cobs.j.max()+1))\n",
    "    pt_carr[lay_cobs.i,lay_cobs.j] = pt_oe_ho.loc[real,lay_cobs.obsnme]\n",
    "\n",
    "    pr_carr[pr_carr<0.001] = np.nan\n",
    "    pt_carr[pt_carr<0.001] = np.nan\n",
    "    \n",
    "\n",
    "    fig,axes = plt.subplots(1,2,figsize=(12,5))\n",
    "    axes[0].imshow(pr_carr,vmin=cmn,vmax=cmx)\n",
    "    cb = axes[1].imshow(pt_carr,vmin=cmn,vmax=cmx)\n",
    "    plt.colorbar(cb,ax=axes[1])\n",
    "    \n",
    "    cs = axes[0].contour(pr_harr,levels=hlevels,colors=\"0.5\")\n",
    "    axes[0].clabel(cs)\n",
    "    cs = axes[1].contour(pt_harr,levels=hlevels,colors=\"0.5\")\n",
    "    axes[1].clabel(cs)\n",
    "    axes[0].set_title(\"{0} prior realization {1}\".format(otag,real))\n",
    "    axes[1].set_title(\"{0} posterior realization {1}\".format(otag,real))\n",
    "    \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335adf76",
   "metadata": {},
   "source": [
    "Not as drastic of a change prior-to-posterior as we saw when using the concentration observations...\n",
    "Now lets compare the simulated mass discharged to the GHBs with and without using concentration observations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3518d94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ghb_mass_onames = obs.loc[obs.obsnme.apply(lambda x: \"tcum\" in x and \"ghb\" in x),\"obsnme\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b34fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ghb_mass_onames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af4fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(np.abs(pt_oe.loc[:,ghb_mass_oname].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d1d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ghb_mass_oname in ghb_mass_onames:\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.hist(np.log10(np.abs(pt_oe.loc[:,ghb_mass_oname].values)),fc=\"m\",alpha=0.5)\n",
    "    ax.hist(np.log10(np.abs(pt_oe_ho.loc[:,ghb_mass_oname].values)),fc=\"c\",alpha=0.5)\n",
    "    ax.set_title(ghb_mass_oname)\n",
    "    ax.set_xlabel(\"$log_{10}$ Kg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53f8677",
   "metadata": {},
   "source": [
    "We see the value of those concentration observations now: the range of mass discharged to the GHBs is narrow when concentration observations are used for history matching - the uncertainty in an important simulation results is lower... \n",
    "\n",
    "Let's do the same plotting for the wel type boundaries, but this time, lets compare the difference in mass removed by the wel boundaries since this is a direct measure of the effectiveness of the pump-and-treat system's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc16e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "well_mass_onames = obs.loc[obs.obsnme.apply(lambda x: \"tcum\" in x and \"wel\" in x),\"obsnme\"]\n",
    "d = pt_oe.loc[:,well_mass_onames[0]].values - pt_oe.loc[:,well_mass_onames[1]].values\n",
    "d_ho = pt_oe_ho.loc[:,well_mass_onames[0]].values - pt_oe_ho.loc[:,well_mass_onames[1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e34c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1)\n",
    "ax.hist(np.log10(d),fc=\"m\",alpha=0.5)\n",
    "ax.hist(np.log10(d_ho),fc=\"c\",alpha=0.5)\n",
    "_ = ax.set_xlabel(\"change in mass removed by wells ($log_{10} Kg$)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba2ba91",
   "metadata": {},
   "source": [
    "boom!  again, the value of the concentration observations is clear:  Those observations have significantly reduce the uncertainty around the mass recovered by the pump-and-treat system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a677c7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
