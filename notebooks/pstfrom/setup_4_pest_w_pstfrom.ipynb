{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48e10c67",
   "metadata": {},
   "source": [
    "# Setting up for PEST(++) analyses\n",
    "\n",
    "In this notebook, we will use the MF6 model that was built using `modflow-setup`.  We will constuct the PEST interface (e.g. template files, instruction files, control file), as well as generate the prior parameter ensemble.  The best part is, this will all be done programmatically! That means whenever \"issues\" are discovered, it is easier to recover..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2c8d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "sys.path.append('../../dependencies/')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import flopy as fp\n",
    "import pyemu\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6783ca6",
   "metadata": {},
   "source": [
    "## preparing for `PstFrom`\n",
    "\n",
    "The `PstFrom` class in `pyEMU` can automate the PEST(++) setup process.  `PstFrom` expects model input and output files to be either array format (2-d homogenous data type) or list format (heterogenous data type by columns).  So this means we need to get the MF6 model to use \"external\" format so that all input quantities we are interested in are stored in stand-alone files. Luckily, `flopy` can do this operation for us..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2716dd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the original directory that holds the MF6 files\n",
    "org_d = os.path.join(\"..\",\"..\",\"models\",\"sgn_mfsetup_transport\")\n",
    "assert os.path.exists(org_d)\n",
    "# the model base name\n",
    "mname = \"sgn_50\"\n",
    "assert os.path.exists(os.path.join(org_d,mname+\".nam\"))\n",
    "# a temporary directory that will hold the model files\n",
    "tmp_d = \"temp\"\n",
    "if os.path.exists(tmp_d):\n",
    "    shutil.rmtree(tmp_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782cdb2c",
   "metadata": {},
   "source": [
    "Load the existing model and convert it to \"external\" input files (arrays and lists).  Having the array and list inputs as external files makes everything in the pest world easier..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714a6c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = fp.mf6.MFSimulation.load(sim_ws=org_d)\n",
    "sim.simulation_data.mfpath.set_sim_path(tmp_d)\n",
    "m = sim.get_model(mname)\n",
    "sim.set_all_data_external(check_data=True)\n",
    "sim.write_simulation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c57ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(tmp_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72c3992",
   "metadata": {},
   "source": [
    "OK!  So we see now that `tmp_d` contains all the MF6 input files and both the array and list quantities are in external files.  Let's make sure the model will run (always important!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59c7751",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.run(\"mf6\",cwd=tmp_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d30a26",
   "metadata": {},
   "source": [
    "Now we are ready to start setting up for PEST(++) with `PstFrom`.  First, let's copy dependecies into the `tmp_d` directory so that they will be carried along|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b664993",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copytree(os.path.join(\"..\",\"..\",\"dependencies\",\"flopy\"),os.path.join(tmp_d,\"flopy\"))\n",
    "shutil.copytree(os.path.join(\"..\",\"..\",\"dependencies\",\"pyemu\"),os.path.join(tmp_d,\"pyemu\"))\n",
    "shutil.copy2(\"helpers.py\",os.path.join(tmp_d,\"helpers.py\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389c7cec",
   "metadata": {},
   "source": [
    "Now let's create our `PstFrom` instance.  It will copy the `tmp_d` to `t_d` directory and then setup the pest interface files in `t_d`, leaving `tmp_d` untouched (nice!).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b692be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_d = \"template\"\n",
    "pf = pyemu.utils.PstFrom(tmp_d,t_d,remove_existing=True,spatial_reference=m.modelgrid,zero_based=False,echo=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7d6201",
   "metadata": {},
   "source": [
    "Now we should have a complete set of model files in `template`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14276ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(t_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d532eac",
   "metadata": {},
   "source": [
    "We see that all the same files from `tmp_d` and now in `t_d`, with the addition of the `flopy` and `pyemu` directories.  Now we are going to create a geostatistical structure that will be used to give us coherent correlation in spatially distributed parameter types (to keep the geologist happy!).  In the absense of direct variogram information, we are going to generate a variogram range that is a function of the cell-spacing of the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46205d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = min(m.dis.delr.data.min(),m.dis.delc.data.min()) * min(m.dis.ncol.data,m.dis.nrow.data) * 0.25\n",
    "print(a)\n",
    "# creat an exponential variogram\n",
    "v = pyemu.geostats.ExpVario(contribution=1.0,a=a)\n",
    "# create a geostruct with the variogram\n",
    "gs = pyemu.geostats.GeoStruct(variograms=v,transform=\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07adaefd",
   "metadata": {},
   "source": [
    "So that is our correlation length.Let's take a look at the geostatistical structure in graphical form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df7bc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = gs.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2041a5c4",
   "metadata": {},
   "source": [
    "Sweet!  Now lets add some parameters.  We will focus on horizontal hydraulic conductivity because, well, we are groundwater modellers and we are crazy about HK!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e417671",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = \"npf_k\"\n",
    "files = [f for f in os.listdir(t_d) if tag in f.lower() and f.endswith(\".txt\")]\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7e1c34",
   "metadata": {},
   "source": [
    "So those are the array files for MF6 that are for HK.  Let's do something fancy:  let's setup multiple spatial scales of parameters for HK.  The coarse scale will be a `constant` single value for each array.  The medium scale will pilot points and the finest scale will use parameters as the `grid` scale - each model cell!  Each scale of parameters will work with the others as multipliers with the existing HK arrays - this all happens at runtime.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f40ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    pf.add_parameters(f,par_type=\"grid\",geostruct=gs,par_name_base=f.split('.')[1]+\"_gr\",pargp=f.split('.')[1]+\"_gr\",\n",
    "                     lower_bound=0.2,upper_bound=5.0)\n",
    "    pf.add_parameters(f,par_type=\"constant\",geostruct=gs,par_name_base=f.split('.')[1]+\"_cn\",\n",
    "                      pargp=f.split('.')[1]+\"_cn\",\n",
    "                     lower_bound=0.2,upper_bound=5.0)\n",
    "    pf.add_parameters(f,par_type=\"pilotpoints\",geostruct=gs,par_name_base=f.split('.')[1]+\"_pp\",\n",
    "                      pargp=f.split('.')[1]+\"_pp\",\n",
    "                     lower_bound=0.2,upper_bound=5.0,pp_space=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3f849d",
   "metadata": {},
   "source": [
    "Boom! that was easy...now lets do the same for recharge (because we can!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e5eca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = \"rcha_recharge\"\n",
    "files = [f for f in os.listdir(t_d) if tag in f.lower() and f.endswith(\".txt\")]\n",
    "print(files)\n",
    "for f in files:\n",
    "    pf.add_parameters(f,par_type=\"grid\",geostruct=gs,par_name_base=f.split('.')[1]+\"_gr\",\n",
    "                      pargp=f.split('.')[1]+\"_gr\",\n",
    "                     lower_bound = 0.8,upper_bound=1.2)\n",
    "    pf.add_parameters(f,par_type=\"constant\",geostruct=gs,par_name_base=f.split('.')[1]+\"_cn\",\n",
    "                      pargp=f.split('.')[1]+\"_cn\",\n",
    "                     lower_bound=0.8,upper_bound=1.2)\n",
    "    pf.add_parameters(f,par_type=\"pilotpoints\",geostruct=gs,par_name_base=f.split('.')[1]+\"_pp\",\n",
    "                      pargp=f.split('.')[1]+\"_pp\",\n",
    "                     lower_bound=0.8,upper_bound=1.2,pp_space=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b22290",
   "metadata": {},
   "source": [
    "And dont forget transport properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0252753",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tag = \"mst_porosity\"\n",
    "files = [f for f in os.listdir(t_d) if tag in f.lower() and f.endswith(\".txt\")]\n",
    "print(files)\n",
    "for f in files:\n",
    "    pf.add_parameters(f,par_type=\"grid\",geostruct=gs,par_name_base=f.split('.')[1]+\"_gr\",\n",
    "                      pargp=f.split('.')[1]+\"_gr\",\n",
    "                     lower_bound = 0.8,upper_bound=1.2,ult_ubound=0.2,ult_lbound=0.01)\n",
    "    pf.add_parameters(f,par_type=\"constant\",geostruct=gs,par_name_base=f.split('.')[1]+\"_cn\",\n",
    "                      pargp=f.split('.')[1]+\"_cn\",\n",
    "                     lower_bound=0.8,upper_bound=1.2,ult_ubound=0.2,ult_lbound=0.01)\n",
    "    pf.add_parameters(f,par_type=\"pilotpoints\",geostruct=gs,par_name_base=f.split('.')[1]+\"_pp\",\n",
    "                      pargp=f.split('.')[1]+\"_pp\",\n",
    "                     lower_bound=0.8,upper_bound=1.2,pp_space=4,ult_ubound=0.2,ult_lbound=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35563d45",
   "metadata": {},
   "source": [
    "Now this will make some people uncomfortable but how well do we really ever know historic water use flux rates in space and in time? hmmm, not really! So lets add parameters to represent that uncertainty in the model inputs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99c1a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = \"wel_stress_period_data\"\n",
    "files = [f for f in os.listdir(t_d) if tag in f.lower() and f.endswith(\".txt\")]\n",
    "print(files)\n",
    "for f in files:\n",
    "    kper = int(f.split('.')[1].split('_')[-1])\n",
    "    name = \"welflux_{0:04d}\".format(kper)\n",
    "    pf.add_parameters(f,par_type=\"grid\",geostruct=gs,par_name_base=name,pargp=name,\n",
    "                     index_cols=[0,1,2],use_cols=[3],lower_bound=0.5,upper_bound=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5321a1e1",
   "metadata": {},
   "source": [
    "What about those ghb stages along the boundaries of the model?  Maybe we should consider their uncertainty also?  Since these boundaries are likely to be very influential, we want to include a robust representation of their uncertainty - both stage and conductance and at multiple scales.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3b36f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = \"ghb_stress_period_data\"\n",
    "files = [f for f in os.listdir(t_d) if tag in f.lower() and f.endswith(\".txt\")]\n",
    "print(files)\n",
    "for f in files:\n",
    "    kper = int(f.split('.')[1].split('_')[-1])\n",
    "    \n",
    "    # constant and grid scale multiplier conductance parameters\n",
    "    name = \"ghbcond_{0:04d}\".format(kper)\n",
    "    pf.add_parameters(f,par_type=\"grid\",geostruct=gs,par_name_base=name+\"_gr\",pargp=name+\"_gr\",\n",
    "                     index_cols=[0,1,2],use_cols=[4],lower_bound=0.1,upper_bound=10.0)\n",
    "    pf.add_parameters(f,par_type=\"constant\",geostruct=gs,par_name_base=name+\"_cn\",pargp=name+\"_cn\",\n",
    "                     index_cols=[0,1,2],use_cols=[4],lower_bound=0.1,upper_bound=10.0)\n",
    "    \n",
    "    # constant and grid scale additive stage parameters\n",
    "    name = \"ghbstage_{0:04d}\".format(kper)\n",
    "    pf.add_parameters(f,par_type=\"grid\",geostruct=gs,par_name_base=name+\"_gr\",pargp=name+\"_gr\",\n",
    "                     index_cols=[0,1,2],use_cols=[3],par_style=\"a\",lower_bound=-2.0,upper_bound=2.0,\n",
    "                     transform=\"none\")\n",
    "    pf.add_parameters(f,par_type=\"constant\",geostruct=gs,par_name_base=name+\"_cn\",pargp=name+\"_cn\",\n",
    "                     index_cols=[0,1,2],use_cols=[3],lower_bound=-2.0,upper_bound=2.0,par_style=\"a\",\n",
    "                     transform=\"none\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6b5078",
   "metadata": {},
   "source": [
    "and who could forget SFR conductance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42e7ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = \"sfr_packagedata\"\n",
    "files = [f for f in os.listdir(t_d) if tag in f.lower() and f.endswith(\".txt\")]\n",
    "assert len(files) == 1\n",
    "print(files)\n",
    "f = files[0]\n",
    "# constant and grid scale multiplier conductance parameters\n",
    "name = \"sfrcond\"\n",
    "pf.add_parameters(f,par_type=\"grid\",geostruct=gs,par_name_base=name+\"_gr\",pargp=name+\"_gr\",\n",
    "                 index_cols=[0,2,3],use_cols=[9],lower_bound=0.1,upper_bound=10.0)\n",
    "pf.add_parameters(f,par_type=\"constant\",geostruct=gs,par_name_base=name+\"_cn\",pargp=name+\"_cn\",\n",
    "                 index_cols=[0,2,3],use_cols=[9],lower_bound=0.1,upper_bound=10.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca12d48",
   "metadata": {},
   "source": [
    "And let's also consider source loading concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ca9888",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = \"cnc_stress_period_data\"\n",
    "files = [f for f in os.listdir(t_d) if tag in f.lower() and f.endswith(\".txt\")]\n",
    "assert len(files) == 1\n",
    "print(files)\n",
    "f = files[0]\n",
    "name = \"cnc\"\n",
    "pf.add_parameters(f,par_type=\"grid\",geostruct=gs,par_name_base=name+\"_gr\",pargp=name+\"_gr\",\n",
    "                 index_cols=[0,1,2],use_cols=[3],lower_bound=0.1,upper_bound=10.0)\n",
    "pf.add_parameters(f,par_type=\"constant\",geostruct=gs,par_name_base=name+\"_cn\",pargp=name+\"_cn\",\n",
    "                 index_cols=[0,1,2],use_cols=[3],lower_bound=0.1,upper_bound=10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb63b4cb",
   "metadata": {},
   "source": [
    "Sweet!  thats heaps of parameters - exactly what we wanted.  Now lets setup some observations in the pest control file.  To start, we need to run a simple post processor that will extract the simulated water levels from the binary headsave file and save to an ASCII file, and also process the list budget file into csv files.  Let's see what is in this helpers script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18138e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "[l.strip() for l in open(\"helpers.py\",'r').readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3750883e",
   "metadata": {},
   "source": [
    "Just some basic python hackery there! The top bit extracts the simulated groundwater levels from the binary headsave file and saves to an ASCII array (why can't MF6 save ASCII???) and the lower part parses the list file for volume budget information. \n",
    "\n",
    "Now lets run this function in the `t_d` directory to generate some output files that we can use for setting up observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718ec57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.run(\"python helpers.py\",cwd=t_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfad56bc",
   "metadata": {},
   "source": [
    "first lets add some sfr observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e5c514",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pf.add_observations(mname+\".sfr.obs.output.csv\",index_cols=0,prefix=\"sw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5624f4",
   "metadata": {},
   "source": [
    "add the MF6 head obs output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca152563",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pf.add_observations(mname+\".head.obs\",index_cols=[0],prefix=\"head\",ofile_sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbbefff",
   "metadata": {},
   "source": [
    "and MF6 concentration obs output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82830ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pf.add_observations(\"conc_obs.csv\",index_cols=[0],prefix=\"concen\",ofile_sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a36b660",
   "metadata": {},
   "source": [
    "lets add a pest observation for every active model cell.  Why?  because we can! and because in an ensemble-based workflow, the cost of getting just one new simulated output is high, so its easier to just carry all the outputs you can think of - its just storage since these outputs arent used for any calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd1463c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hds_files = [f for f in os.listdir(t_d) if f.endswith(\"hds.dat\")]\n",
    "assert len(hds_files) == m.dis.nlay.data,len(hds_files)\n",
    "for hds_file in hds_files:\n",
    "    pf.add_observations(hds_file,obsgp=hds_file.split('.')[1],prefix=hds_file.split('.')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff3a209",
   "metadata": {},
   "source": [
    "And the same for simulated concentrations...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371f9f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "ucn_files = [f for f in os.listdir(t_d) if f.endswith(\"ucn.dat\")]\n",
    "assert len(ucn_files) == m.dis.nlay.data\n",
    "for ucn_file in ucn_files:\n",
    "    pf.add_observations(ucn_file,obsgp=ucn_file.split('.')[1],prefix=ucn_file.split('.')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94760c0",
   "metadata": {},
   "source": [
    "And also observations for the cumulative and incremental list file budget - these are great diagnostic quantities to keep track of!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfb282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(t_d,\"inc.csv\"),index_col=0)\n",
    "pf.add_observations(\"inc.csv\",index_cols=[\"time\"],use_cols=df.columns.tolist(),obsgp=\"inc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab232fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(t_d,\"tcum.csv\"),index_col=0)\n",
    "pf.add_observations(\"tcum.csv\",index_cols=[\"time\"],use_cols=df.columns.tolist(),obsgp=\"tcum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dceadf",
   "metadata": {},
   "source": [
    "Always a good idea to remove intermediate processing files to help prevent them getting used erroneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57265f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.tmp_files.append(mname+\".hds\")\n",
    "pf.tmp_files.append(\"gwt-sgn.ucn\")\n",
    "pf.tmp_files.append(mname+\".list\")\n",
    "pf.tmp_files.append(\"gwt-sgn.list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1c7161",
   "metadata": {},
   "source": [
    "Now we need to tell `PstFrom` that we want that `helpers.py` script to run after MF6, every time that MF6 runs. We will use a method that reads python source files and extracts functions (wat?!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a377df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.add_py_function(\"helpers.py\",\"postproc()\",is_pre_cmd=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2f318f",
   "metadata": {},
   "source": [
    "Now we just need to set the model run command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b968533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.mod_sys_cmds.append(\"mf6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93179914",
   "metadata": {},
   "source": [
    "Magic time!:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca20f7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.build_pst()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b434ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "[f for f in os.listdir(t_d) if f[-3:] in [\"pst\",\"tpl\",\"ins\",\".py\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af5bc9a",
   "metadata": {},
   "source": [
    "Everything we need to run PEST(++) is now in `t_d`.   Let's checkout `temp.pst`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad62a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "open(os.path.join(t_d,\"temp.pst\"),'r').readlines()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755d2c37",
   "metadata": {},
   "source": [
    "We just built a very-high dimensional PEST interface - snap!\n",
    "\n",
    "Now, lets generate a prior parameter ensemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c132ed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = pf.draw(num_reals=100,use_specsim=True)\n",
    "pe.enforce()\n",
    "pe.to_binary(os.path.join(t_d,\"prior.jcb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315a594e",
   "metadata": {},
   "source": [
    "Boom!  We now have a geostatistically correlated prior parameter ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf64c4c6",
   "metadata": {},
   "source": [
    "We can use all the standard `pandas` action the `ParameterEnsemble` instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17112319",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pe.iloc[:,0].hist()\n",
    "_ = ax.set_title(pe.columns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fe4611",
   "metadata": {},
   "source": [
    "Kewl - now lets test a single run of the process, just to make sure everything is working as expected..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b83f446",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.pst.control_data.noptmax = 0\n",
    "# lets tell pest++ where we stored the prior parameter ensemble\n",
    "pf.pst.pestpp_options[\"ies_par_en\"] = \"prior.jcb\"\n",
    "pf.pst.observation_data.loc[:,\"weight\"] = 1.0\n",
    "pf.pst.write(os.path.join(t_d,\"sgn.pst\"),version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e77d60f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pyemu.os_utils.run(\"pestpp-ies sgn.pst\",cwd=t_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434a9b75",
   "metadata": {},
   "source": [
    "Nice! Since we have not adjusted the observation data or parameters, and the observation values in the control file are just the values in the existing output files, we expect the objective function value to be at or very near 0.0. Let's run the mean parameter values in the prior parameter ensemble - this is done with `noptmax=-2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d7e5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.pst.control_data.noptmax = -2\n",
    "pf.pst.write(os.path.join(t_d,\"sgn.pst\"),version=2)\n",
    "pyemu.os_utils.run(\"pestpp-ies sgn.pst\",cwd=t_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbe9711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72d6f3ae",
   "metadata": {},
   "source": [
    "Now, lets run a single stochastic parameter realization, just to see how that works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e31f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.pst.parameter_data.loc[:,\"parval1\"] = pe.loc[pe.index[0],pf.pst.par_names].values\n",
    "pf.pst.control_data.noptmax = 0\n",
    "pf.pst.write(os.path.join(t_d,\"sgn_test.pst\"),version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f6ceac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pyemu.os_utils.run(\"pestpp-ies sgn_test.pst\",cwd=t_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8021494",
   "metadata": {},
   "source": [
    "Ok, now the phi is higher, as expected.  Let's visualize the MF6 HK input array for this realization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad0c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9e46e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.loadtxt(os.path.join(t_d,mname+\".npf_k_layer1.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23c53ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(arr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50aedac",
   "metadata": {},
   "source": [
    "That should make a geologist happy!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001b2c5d",
   "metadata": {},
   "source": [
    "# Setting observation values and weights\n",
    "\n",
    "This is always painful!.  So we are gonna load up the control file and the hob file we found floating around.  Then we are gonna assign the `obsval` quantities to the observations in the control file that correspond to the hob observed quantities.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5b393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(t_d,\"sgn.pst\"))\n",
    "\n",
    "hob = pd.read_csv(\"gv39.hob\",delim_whitespace=True,skiprows=4,header=None,names=[\"site\",\"l\",\"r\",\"c\",\"obsval\"],usecols=[0,1,2,3,8])\n",
    "hob.site = hob.site.str.lower()\n",
    "hob.index = hob.site\n",
    "obs = pst.observation_data\n",
    "obs.loc[:,\"weight\"] = 0.0\n",
    "# adding the \"_time\" suffix causes us to only use layer 1 obs...\n",
    "hob.loc[:,\"obsnme\"] = hob.apply(lambda x: [o for o in obs.obsnme if x.site+\"_time\" in o],axis=1)\n",
    "hob.loc[:,\"obsnme\"] = hob.obsnme.apply(lambda x: x[0] if len(x)==1 else np.NaN)\n",
    "hob.dropna(inplace=True)\n",
    "hob.index = hob.obsnme\n",
    "obs.loc[hob.obsnme,\"obsval\"] = hob.obsval\n",
    "obs.loc[hob.obsnme,\"weight\"] = 3.0\n",
    "pst.nnz_obs_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9b744c",
   "metadata": {},
   "source": [
    "Let's also set the obsvals for the concentration obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a615f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cob = pd.read_csv(\"pce_obsval.csv\")\n",
    "cob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50104544",
   "metadata": {},
   "source": [
    "Ok, now we can save this control file and have some fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c14802",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.control_data.noptmax = -1\n",
    "pst.write(os.path.join(t_d,\"sgn.pst\"),version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4b1928",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pyemu.os_utils.start_workers(pf.new_d,\"pestpp-ies\",\"sgn.pst\",num_workers=10,master_dir=\"master_prior_mc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e04e9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pyemu.plot_utils.ensemble_helper({\"r\":os.path.join(\"master_prior_mc\",\"sgn.obs+noise.csv\"),\n",
    "                                  \"0.5\":os.path.join(\"master_prior_mc\",\"sgn.0.obs.csv\")},\n",
    "                                 plot_cols=pst.nnz_obs_names,bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902bf7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.control_data.noptmax = 4\n",
    "pst.pestpp_options[\"ies_no_noise\"] = True\n",
    "pst.write(os.path.join(t_d,\"sgn.pst\"),version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db616882",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pyemu.os_utils.start_workers(pf.new_d,\"pestpp-ies\",\"sgn.pst\",num_workers=10,master_dir=\"master_ies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7f6008",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pyemu.plot_utils.ensemble_helper({\"r\":os.path.join(\"master_ies\",\"sgn.obs+noise.csv\"),\n",
    "                                  \"0.5\":os.path.join(\"master_ies\",\"sgn.0.obs.csv\"),\n",
    "                                 \"b\":os.path.join(\"master_ies\",\"sgn.2.obs.csv\")},\n",
    "                                 plot_cols=pst.nnz_obs_names,bins=20,sync_bins=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f21631d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
